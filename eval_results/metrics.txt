== Window-level metrics ==
Acc=0.8734  Recall=0.8734  F1=0.9324  AUC=nan
Confusion Matrix:
[[   0    0]
 [ 291 2008]]

              precision    recall  f1-score   support

           0     0.0000    0.0000    0.0000         0
           1     1.0000    0.8734    0.9324      2299

    accuracy                         0.8734      2299
   macro avg     0.5000    0.4367    0.4662      2299
weighted avg     1.0000    0.8734    0.9324      2299

== Best Threshold (by F1, windows) ==
{
  "th": 0.05,
  "f1": 0.999782466826191,
  "recall": 0.9995650282731623,
  "precision": 1.0
}