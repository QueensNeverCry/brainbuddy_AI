import os
import clip
import torch
from PIL import Image, UnidentifiedImageError
import numpy as np
import pandas as pd

# ì¥ì¹˜ ì„¤ì •
try:
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load("ViT-B/32", device=device)
except RuntimeError as e:
    print(f"âš ï¸ GPU ì˜¤ë¥˜, CPUë¡œ ì¬ì‹œë„: {e}")
    device = "cpu"
    model, preprocess = clip.load("ViT-B/32", device=device)

# í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ëˆˆë™ì + ìì„¸ ê¸°ë°˜ ì§‘ì¤‘/ë¹„ì§‘ì¤‘ í‘œí˜„)
prompts = [
    "a face where the eyes and body are aligned and focused on the same point, indicating concentration",
    "a face where the eyes and body are not aligned or not looking at the same point, indicating lack of focus"
]
text_tokens = clip.tokenize(prompts).to(device)
with torch.no_grad():
    text_features = model.encode_text(text_tokens)
    text_features /= text_features.norm(dim=-1, keepdim=True)

# í•˜ìœ„ í´ë”ê¹Œì§€ ì´ë¯¸ì§€ í¬í•¨ ì—¬ë¶€ í™•ì¸
def find_all_face_crop_folders(folders):
    valid_folders = []
    for root in folders:
        if not os.path.exists(root):
            continue
        for sub in os.listdir(root):
            sub_path = os.path.join(root, sub)
            if os.path.isdir(sub_path):
                image_files = [f for f in os.listdir(sub_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
                if image_files:
                    valid_folders.append(sub_path)
    return valid_folders

# ë¼ë²¨ë§ í•¨ìˆ˜
def label_sequence(folder_path):
    image_features = []
    print(f"\nğŸ“‚ ì´ë¯¸ì§€ í™•ì¸ ì¤‘: {folder_path}")
    try:
        file_list = os.listdir(folder_path)
    except Exception as e:
        print(f"âŒ í´ë” ì ‘ê·¼ ì‹¤íŒ¨: {folder_path} â†’ {e}")
        return None

    for fname in sorted(file_list):
        if fname.lower().endswith(('.png', '.jpg', '.jpeg')):
            img_path = os.path.join(folder_path, fname)
            print(f"  ğŸ” {fname}")
            try:
                with Image.open(img_path) as img:
                    image = preprocess(img).unsqueeze(0).to(device)
                    with torch.no_grad():
                        feat = model.encode_image(image)
                        feat /= feat.norm(dim=-1, keepdim=True)
                        image_features.append(feat.cpu().numpy())
            except Exception as e:
                print(f"âš ï¸ ì²˜ë¦¬ ì‹¤íŒ¨: {img_path} â†’ {e}")
                continue

    if len(image_features) == 0:
        print(f"â›” ì´ë¯¸ì§€ ì—†ìŒ: {folder_path}")
        return None

    avg_feat = torch.tensor(np.mean(np.vstack(image_features), axis=0)).unsqueeze(0).to(device)
    similarity = (avg_feat @ text_features.T).softmax(dim=-1).squeeze().cpu().numpy()
    print(f"âœ… ë¼ë²¨ë§ ì™„ë£Œ: {folder_path} â†’ {similarity}")
    return similarity

root_dirs = [
    r"C:/Users/user/Downloads/126.eye/0801/t/o/og/TS/TS/all_image_30/134_face_crop",
    r"C:/Users/user/Downloads/126.eye/0801/t/o/og/TS/TS/all_image_30/135_face_crop",
    r"C:/Users/user/Downloads/126.eye/0801/t/o/og/TS/TS/all_image_30/136_face_crop",
    r"C:/Users/user/Downloads/126.eye/01-1.data/Training/01.data/TS/001/T1/image_30_face_crop",
    r"C:/Users/user/Downloads/126.eye/01-1.data/Training/01.data/TS/002/T1/image_30_face_crop",
    r"C:/Users/user/Downloads/126.eye/01-1.data/Training/01.data/TS/003/T1/image_30_face_crop"
]


# ì „ì²´ ì‹¤í–‰
results = []
folders = find_all_face_crop_folders(root_dirs)

for folder in folders:
    print(f"\nâ–¶ï¸ í´ë” ì²˜ë¦¬ ì¤‘: {folder}")
    sim = label_sequence(folder)
    if sim is None:
        continue
    pred_label = int(np.argmax(sim))
    results.append({
        "folder": folder,
        "focused": sim[0],
        "unfocused": sim[1],
        "predicted_label": pred_label
    })

# CSV ì €ì¥
if results:
    df = pd.DataFrame(results)
    df.to_csv("vlm_labeled_results_binary.csv", index=False)
    print("\nğŸ“ ì´ì§„ ë¼ë²¨ë§ ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ 'vlm_labeled_results_binary.csv'")
else:
    print("\nâš ï¸ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ê²½ë¡œì™€ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
