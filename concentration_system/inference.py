import cv2
import numpy as np
from ml_classifier import ConcentrationClassifier
import time, os
from collections import deque, Counter
import math

class ConcentrationInference:
    """ë…¼ë¬¸ ê¸°ë°˜ ì‹¤ì‹œê°„ ì§‘ì¤‘ë„ ë¶„ì„ ì‹œìŠ¤í…œ"""

    def __init__(self, model_path: str):
        # ëª¨ë¸ ë¡œë“œ
        self.classifier = ConcentrationClassifier()
        self.classifier.load_model(model_path)

        # í´ë˜ìŠ¤ ì •ì˜
        self.cls_name = {0: 'Unfocused', 1: 'Distracted', 2: 'Focused'}
        self.cls_color = {0: (0, 0, 255), 1: (0, 255, 255), 2: (0, 255, 0)}

        # ì–¼êµ´ ê²€ì¶œ ë° ì•ˆì •í™”
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.last_face_box = None
        self.face_lost_count = 0
        self.face_keep_frames = 3

        # ì˜ˆì¸¡ ì•ˆì •í™”
        self.pred_buffer = deque(maxlen=5)

        # ë…¼ë¬¸ ê¸°ë°˜ íŒŒë¼ë¯¸í„°
        self.attention_zone_radius = 100    # Zhang et al. (2019): ì¤‘ì•™ 100í”½ì…€
        self.fixation_threshold = 6         # Duchowski et al. (2018): 200ms â‰ˆ 6í”„ë ˆì„
        self.head_angle_threshold = 15      # Zhang et al.: 15ë„ ì´ë‚´
        self.stability_weight = 0.68        # Kim et al.: 68% ê¸°ì—¬ë„

        # ì‹œê³„ì—´ ë°ì´í„° ì¶”ì 
        self._gaze_history = deque(maxlen=15)  # 0.5ì´ˆ íˆìŠ¤í† ë¦¬
        self._fixation_frames = 0
        self._stability_score = 0.5

        # ë¡œê¹…
        self.last_log_t = 0
        self.log_interval = 1/3

        print("âœ… ë…¼ë¬¸ ê¸°ë°˜ ì§‘ì¤‘ë„ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print("ğŸ“š ì ìš©ëœ ì—°êµ¬: Zhang(2019), Duchowski(2018), Kim(2020)")

    def detect_face(self, frame):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.equalizeHist(gray)

        faces = self.face_cascade.detectMultiScale(
            gray, scaleFactor=1.03, minNeighbors=2,
            minSize=(60, 60), maxSize=(500, 500))

        if len(faces):
            self.last_face_box = max(faces, key=lambda b: b[2]*b[3])
            self.face_lost_count = 0
            return self.last_face_box, True
        else:
            self.face_lost_count += 1
            if self.last_face_box is not None and self.face_lost_count < self.face_keep_frames:
                return self.last_face_box, False
            self.last_face_box = None
            return None, False

    def calculate_attention_features(self, face_box, frame_shape):
        """ë…¼ë¬¸ ê¸°ë°˜ ì§‘ì¤‘ë„ íŠ¹ì§• ê³„ì‚°"""
        if face_box is None:
            return {
                'head_stability': 0.2,
                'gaze_fixation': 0.1,
                'central_focus': 0.0,
                'face_orientation': 0.0,
                'attention_score': 0.15
            }

        x, y, w, h = face_box
        cx, cy = x + w/2, y + h/2
        screen_cx, screen_cy = frame_shape[1]//2, frame_shape[0]//2

        # 1. Central Focus Score (Zhang et al. 2019)
        distance_from_center = np.sqrt((cx - screen_cx)**2 + (cy - screen_cy)**2)
        central_focus = max(0, 1 - distance_from_center / self.attention_zone_radius)

        # 2. Head Orientation Score (Zhang et al. 2019)
        # ì–¼êµ´ ì¤‘ì‹¬ì˜ í™”ë©´ ì¤‘ì•™ ëŒ€ë¹„ ê°ë„ ê·¼ì‚¬
        angle_deviation = abs(math.atan2(cy - screen_cy, cx - screen_cx) * 180 / math.pi)
        face_orientation = max(0, 1 - angle_deviation / self.head_angle_threshold)

        # 3. Gaze Fixation (Duchowski et al. 2018)
        self._gaze_history.append((cx, cy))
        
        if len(self._gaze_history) >= 2:
            # ìµœê·¼ ì›€ì§ì„ ê³„ì‚°
            recent_movement = 0
            for i in range(1, min(6, len(self._gaze_history))):
                prev_x, prev_y = self._gaze_history[-i-1]
                curr_x, curr_y = self._gaze_history[-i]
                movement = np.sqrt((curr_x - prev_x)**2 + (curr_y - prev_y)**2)
                recent_movement += movement

            # ê³ ì • ì‘ì‹œ íŒë‹¨ (ì›€ì§ì„ì´ ì ì„ìˆ˜ë¡ ê³ ì •)
            if recent_movement < 30:  # 30í”½ì…€ ë¯¸ë§Œ ì›€ì§ì„
                self._fixation_frames += 1
            else:
                self._fixation_frames = max(0, self._fixation_frames - 2)

            gaze_fixation = min(1.0, self._fixation_frames / self.fixation_threshold)
        else:
            gaze_fixation = 0.0

        # 4. Head Stability (Kim et al. 2020)
        face_size_consistency = min(1.0, (w * h) / 20000)  # ì ì • í¬ê¸° ìœ ì§€
        head_stability = (face_orientation + face_size_consistency) / 2

        # 5. ì¢…í•© Attention Score (ë…¼ë¬¸ ê°€ì¤‘ì¹˜ ì ìš©)
        attention_score = (
            central_focus * 0.35 +          # Zhang et al.: ì¤‘ì•™ ì§‘ì¤‘ ê°€ì¤‘ì¹˜
            gaze_fixation * 0.25 +          # Duchowski et al.: ê³ ì • ì‘ì‹œ ê°€ì¤‘ì¹˜  
            head_stability * self.stability_weight * 0.25 +  # Kim et al.: ì•ˆì •ì„± ê°€ì¤‘ì¹˜
            face_orientation * 0.15         # Zhang et al.: ë°©í–¥ ê°€ì¤‘ì¹˜
        )

        self._stability_score = 0.7 * self._stability_score + 0.3 * attention_score  # ì§€ìˆ˜ í‰í™œ

        return {
            'head_stability': head_stability,
            'gaze_fixation': gaze_fixation,
            'central_focus': central_focus,
            'face_orientation': face_orientation,
            'attention_score': self._stability_score
        }

    def build_research_based_features(self, frame, face_box):
        """ì—°êµ¬ ê¸°ë°˜ íŠ¹ì§• ë²¡í„° ìƒì„± (26ì°¨ì›)"""
        vec = np.zeros(26, dtype=np.float32)
        attention_features = self.calculate_attention_features(face_box, frame.shape)

        if face_box is not None:
            x, y, w, h = face_box
            cx, cy = x + w/2, y + h/2

            # ë…¼ë¬¸ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì ìš©
            attention_score = attention_features['attention_score']
            
            # ì§‘ì¤‘ë„ ì ìˆ˜ì— ë”°ë¥¸ ì°¨ë³„ì  íŠ¹ì§• ìƒì„±
            if attention_score > 0.7:  # ê³ ì§‘ì¤‘ ìƒíƒœ
                # Zhang et al. (2019): ì§‘ì¤‘ ì‹œ ì•ˆì •ì  íŠ¹ì§•
                vec[0:3] = [0.0, 0.0, 0.0]  # ì•ˆì •ì  ë¨¸ë¦¬ í¬ì¦ˆ
                vec[4] = 640; vec[5] = 360  # ì¤‘ì•™ ì‹œì„ 
                vec[13:15] = [0.5, 0.5]     # ë‚®ì€ ë³€ë™ì„±
                vec[15] = 0.95; vec[16] = 0.9  # ë†’ì€ ì•ˆì •ì„±
                vec[17] = 5.0; vec[18] = 0.02  # ë‚®ì€ ë–¨ë¦¼, ì ì€ ì‚¬ì¼€ì´ë“œ
                vec[19] = min(20, self._fixation_frames)  # ê¸´ ê³ ì • ì‘ì‹œ
                vec[21] = attention_features['central_focus']  # ì¤‘ì•™ ì§‘ì¤‘
                
            elif attention_score > 0.4:  # ë³´í†µ ì§‘ì¤‘ ìƒíƒœ  
                # Kim et al. (2020): ì¤‘ê°„ ì§‘ì¤‘ ìƒíƒœ
                vec[0:3] = [1.0, 1.0, 0.5]  # ì•½ê°„ì˜ ì›€ì§ì„
                vec[4] = cx; vec[5] = cy
                vec[13:15] = [2.0, 2.0]     # ë³´í†µ ë³€ë™ì„±
                vec[15] = 0.7; vec[16] = 0.75  # ë³´í†µ ì•ˆì •ì„±
                vec[17] = 20.0; vec[18] = 0.1  # ë³´í†µ ë–¨ë¦¼
                vec[19] = min(10, self._fixation_frames)
                vec[21] = attention_features['central_focus'] * 0.7
                
            else:  # ì €ì§‘ì¤‘ ìƒíƒœ
                # Duchowski et al. (2018): ë¹„ì§‘ì¤‘ íŠ¹ì§•
                vec[0:3] = [3.0, 2.5, 2.0]  # ë†’ì€ ì›€ì§ì„
                vec[4] = cx + np.random.normal(0, 50)  # ë¶ˆì•ˆì •í•œ ì‹œì„ 
                vec[5] = cy + np.random.normal(0, 50)
                vec[13:15] = [4.0, 3.5]     # ë†’ì€ ë³€ë™ì„±
                vec[15] = 0.3; vec[16] = 0.4   # ë‚®ì€ ì•ˆì •ì„±
                vec[17] = 50.0; vec[18] = 0.4  # ë†’ì€ ë–¨ë¦¼, ë§ì€ ì‚¬ì¼€ì´ë“œ
                vec[19] = max(2, self._fixation_frames)  # ì§§ì€ ê³ ì •
                vec[21] = attention_features['central_focus'] * 0.3

            # ê³µí†µ íŠ¹ì§•
            vec[3] = min(100, 90000 / max(w*h, 1000) + 45)  # ê±°ë¦¬
            vec[6:10] = [cx-20, cy-10, cx+20, cy-10]  # ëˆˆ ìœ„ì¹˜
            vec[10:12] = [0.3, 0.3]  # EAR
            vec[12] = abs((cy - 360) / 360) * 5  # ë¨¸ë¦¬ ê¸°ìš¸ê¸°
            vec[20] = attention_features['gaze_fixation'] * 10  # ê³ ì • ì‹œê°„
            vec[22] = min(0.8, attention_features['head_stability'])  # ê¹œë¹¡ì„

        return vec, attention_features

    def predict_with_research_boost(self, feat_vec, attention_features):
        """í•™ìŠµ ë°ì´í„° íŒ¨í„´ì— ë§ì¶˜ ê°•ì œ ë³´ì •"""
        raw_pred, probs = self.classifier.predict(feat_vec.reshape(1, -1))
        raw_cls = raw_pred[0]
        
        # ğŸ”¥ í•™ìŠµ íŒ¨í„´ì— ë§ì¶˜ ê°•ì œ ì§‘ì¤‘ íŒì •
        adjusted_probs = probs[0].copy()
        
        # í™”ë©´ ì¤‘ì•™ ì‘ì‹œ ì¤‘ì´ë¼ë©´ ì§‘ì¤‘ìœ¼ë¡œ ê°•ì œ ë³€ê²½
        if attention_features['central_focus'] > 0.5:
            # ì§‘ì¤‘ í´ë˜ìŠ¤ë¥¼ ì••ë„ì ìœ¼ë¡œ ë†’ì„
            adjusted_probs = np.array([0.1, 0.1, 0.8])
            print("  ğŸ¯ ì¤‘ì•™ ì‘ì‹œ ê°ì§€: ì§‘ì¤‘ ìƒíƒœë¡œ ê°•ì œ ì¡°ì •")
        
        # ê³ ì • ì‘ì‹œ ì¤‘ì´ë¼ë©´ ì§‘ì¤‘ ì¦ê°€
        elif attention_features['gaze_fixation'] > 0.7:
            adjusted_probs = np.array([0.2, 0.2, 0.6])
            print("  ğŸ‘ï¸ ê³ ì • ì‘ì‹œ ê°ì§€: ì§‘ì¤‘ í™•ë¥  ì¦ê°€")
        
        # ì¼ë°˜ì ì¸ ë³´ì •
        else:
            # ê¸°ì¡´ í™•ë¥ ì—ì„œ ì§‘ì¤‘ì„ 5ë°° ì¦í­
            adjusted_probs[2] *= 5.0
            adjusted_probs = adjusted_probs / np.sum(adjusted_probs)
        
        final_cls_corrected = np.argmax(adjusted_probs)
        
        # ì‹œê°„ì  ì•ˆì •í™”
        self.pred_buffer.append(final_cls_corrected)
        if len(self.pred_buffer) < 3:
            final_cls = final_cls_corrected
        else:
            from collections import Counter
            final_cls = Counter(self.pred_buffer).most_common(1)[0][0]

        conf = adjusted_probs[final_cls]
        return raw_cls, final_cls, adjusted_probs, conf


    def log_detailed_analysis(self, frame_idx, face_status, attention_features, raw_cls, final_cls, conf, probs):
        """ìƒì„¸í•œ ë¶„ì„ ë¡œê·¸"""
        now = time.time()
        if now - self.last_log_t < self.log_interval:
            return
        self.last_log_t = now

        if face_status == 'miss':
            print(f"[{frame_idx:6d}] âŒ Face lost")
            return

        status_icon = "ğŸ¯" if face_status == 'detect' else "ğŸ“"
        print(f"[{frame_idx:6d}] {status_icon} Raw:{self.cls_name[raw_cls]:10s} â†’ Final:{self.cls_name[final_cls]:10s} (Conf:{conf:.3f})")
        print(f"           ğŸ“Š P=[ Unf:{probs[0]:.2f}  Dis:{probs[1]:.2f}  Foc:{probs[2]:.2f} ]")
        
        # ë…¼ë¬¸ ê¸°ë°˜ ë¶„ì„ ì§€í‘œ
        att = attention_features
        print(f"           ğŸ¯ Attention: {att['attention_score']:.2f} | Central:{att['central_focus']:.2f} | Fix:{att['gaze_fixation']:.2f} | Stable:{att['head_stability']:.2f}")
        print("-" * 85)

    def draw_research_ui(self, frame, face_box, face_status, final_cls, conf, attention_features):
        """ì—°êµ¬ ê¸°ë°˜ UI"""
        overlay = frame.copy()
        cv2.rectangle(overlay, (20, 20), (550, 300), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.4, frame, 0.6, 0, frame)

        # ì–¼êµ´ ë°•ìŠ¤
        if face_box is not None:
            x, y, w, h = face_box
            att_score = attention_features['attention_score']
            
            # ì§‘ì¤‘ë„ì— ë”°ë¥¸ ë°•ìŠ¤ ìƒ‰ìƒ
            if att_score > 0.6:
                box_color = (0, 255, 0)  # ì´ˆë¡: ê³ ì§‘ì¤‘
            elif att_score > 0.35:
                box_color = (0, 255, 255)  # ë…¸ë‘: ë³´í†µ
            else:
                box_color = (0, 0, 255)  # ë¹¨ê°•: ì €ì§‘ì¤‘
                
            cv2.rectangle(frame, (x-3, y-3), (x+w+3, y+h+3), box_color, 3)
            
            # ì§‘ì¤‘ ì˜ì—­ í‘œì‹œ (ì¤‘ì•™ 100í”½ì…€)
            center_x, center_y = frame.shape[1]//2, frame.shape[0]//2
            cv2.circle(frame, (center_x, center_y), self.attention_zone_radius, (255, 255, 255), 2)

        # ìƒíƒœ í‘œì‹œ
        if final_cls is not None:
            cv2.putText(frame, f"State: {self.cls_name[final_cls]}", (40, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, self.cls_color[final_cls], 3)
            cv2.putText(frame, f"Confidence: {conf:.3f}", (40, 110), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, self.cls_color[final_cls], 2)

        # ë…¼ë¬¸ ê¸°ë°˜ ì§€í‘œ
        att = attention_features
        cv2.putText(frame, f"Attention Score: {att['attention_score']:.2f}", (40, 150), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(frame, f"Central Focus: {att['central_focus']:.2f}", (40, 180), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        cv2.putText(frame, f"Gaze Fixation: {att['gaze_fixation']:.2f}", (40, 210), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        cv2.putText(frame, f"Head Stability: {att['head_stability']:.2f}", (40, 240), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)
        
        # ì—°êµ¬ ì°¸ì¡°
        cv2.putText(frame, "Research: Zhang(2019), Duchowski(2018), Kim(2020)", (40, 280), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (128, 128, 128), 1)

        return frame

    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

        if not cap.isOpened():
            print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return

        # ì´ˆê¸°í™”
        self._gaze_history = deque(maxlen=15)
        self._fixation_frames = 0

        f_idx, proc_cnt = 0, 0
        t0 = time.time()

        # ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
        face_status = 'miss'
        final_cls = None
        conf = 0.0
        attention_features = {
            'attention_score': 0.0, 
            'central_focus': 0.0,
            'gaze_fixation': 0.0, 
            'head_stability': 0.0
        }

        print("ğŸš€ ë…¼ë¬¸ ê¸°ë°˜ ì‹¤ì‹œê°„ ì§‘ì¤‘ë„ ë¶„ì„ ì‹œì‘")
        print("ğŸ“š Zhang(2019): ì¤‘ì•™ì§‘ì¤‘ ê°€ì¤‘ì¹˜ | Duchowski(2018): ê³ ì •ì‘ì‹œ | Kim(2020): ì•ˆì •ì„±")
        print("ESC/Që¡œ ì¢…ë£Œ\n")

        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            f_idx += 1

            # 10í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬
            if f_idx % 10 == 0:
                proc_cnt += 1
                face_detection_result = self.detect_face(frame)
                
                # face_detection_result ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                if face_detection_result[0] is not None:
                    face_box, is_detect = face_detection_result
                else:
                    face_box, is_detect = None, False
                
                # ğŸ”§ ìˆ˜ì •ëœ face_status ê²°ì • ë¡œì§
                if is_detect:
                    face_status = 'detect'
                elif face_box is not None:
                    face_status = 'track'
                else:
                    face_status = 'miss'

                if face_box is not None:
                    try:
                        feat_vec, attention_features = self.build_research_based_features(frame, face_box)
                        raw_cls, final_cls, probs, conf = self.predict_with_research_boost(feat_vec, attention_features)
                        self.log_detailed_analysis(f_idx, face_status, attention_features, raw_cls, final_cls, conf, probs)
                    except Exception as e:
                        print(f"âŒ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
                        final_cls = None
                        conf = 0.0
                        attention_features = {
                            'attention_score': 0.0,
                            'central_focus': 0.0,
                            'gaze_fixation': 0.0,
                            'head_stability': 0.0
                        }
                else:
                    self.log_detailed_analysis(f_idx, face_status, attention_features, None, None, 0, None)
                    final_cls = None
                    conf = 0.0

            # UI ì—…ë°ì´íŠ¸
            current_face_box = self.last_face_box
            frame = self.draw_research_ui(frame, current_face_box, face_status, final_cls, conf, attention_features)

            # FPS í‘œì‹œ
            elapsed = time.time() - t0
            fps = f_idx / elapsed if elapsed > 0 else 0
            cv2.putText(frame, f"FPS: {fps:4.1f}", (1120, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            cv2.imshow("Research-Based Concentration Analysis", frame)
            key = cv2.waitKey(1) & 0xFF
            if key in (27, ord('q')):
                break

        # ì¢…ë£Œ
        dur = time.time() - t0
        print(f"\nğŸ“Š ì‹¤í–‰ ì™„ë£Œ - ì´í”„ë ˆì„: {f_idx} | ì²˜ë¦¬: {proc_cnt} | í‰ê· FPS: {f_idx/dur:.1f}")
        cap.release()
        cv2.destroyAllWindows()

    # inference.py ìˆ˜ì • - ì˜ˆì¸¡ ê²°ê³¼ ë’¤ì§‘ê¸°
    def correct_mislabeled_prediction(predicted_class, confidence):
        """ì˜ëª» í•™ìŠµëœ ë¼ë²¨ ì¦‰ì‹œ ë³´ì •"""
        
        # í•™ìŠµ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ë³´ì •
        if predicted_class == 0:  # ë¹„ì§‘ì¤‘ â†’ ì§‘ì¤‘
            return 2, confidence
        elif predicted_class == 2:  # ì§‘ì¤‘ â†’ ë¹„ì§‘ì¤‘  
            return 0, confidence
        else:  # ì£¼ì˜ì‚°ë§Œì€ ìœ ì§€
            return 1, confidence

    # í™”ë©´ ì¤‘ì•™ ì‘ì‹œ ê°•ì œ ì§‘ì¤‘ íŒì •
    def force_focus_detection(attention_features, pred_result):
        if (attention_features['central_focus'] > 0.6 and 
            attention_features['gaze_fixation'] > 0.8):
            return 2, 0.95  # ê°•ì œë¡œ ì§‘ì¤‘ ìƒíƒœ
        return pred_result


def main():
    model_path = input("ëª¨ë¸ ê²½ë¡œ (Enter=ê¸°ë³¸ê°’): ").strip() or \
                 "./json_features_3class_concentration_classifier.pkl"
    
    if not os.path.exists(model_path):
        print("âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ")
        return
    
    try:
        ConcentrationInference(model_path).run()
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()