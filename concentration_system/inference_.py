import cv2
import numpy as np
from ml_classifier import ConcentrationClassifier
import time, os
from collections import deque, Counter
import math


class ConcentrationInference:
    """ë…¼ë¬¸ ê¸°ë°˜ ì‹¤ì‹œê°„ ì§‘ì¤‘ë„ ë¶„ì„ ì‹œìŠ¤í…œ (30í”„ë ˆì„ë‹¹ 0/1 ì¶œë ¥)"""

    def __init__(self, model_path: str):
        # ëª¨ë¸ ë¡œë“œ
        self.classifier = ConcentrationClassifier()
        self.classifier.load_model(model_path)

        # ğŸ”¥ 2í´ë˜ìŠ¤ ì •ì˜ë¡œ ë³€ê²½
        self.cls_name = {0: 'Not Focused', 1: 'Focused'}
        self.cls_color = {0: (0, 0, 255), 1: (0, 255, 0)}  # ë¹¨ê°•, ì´ˆë¡

        # ì–¼êµ´ ê²€ì¶œ ë° ì•ˆì •í™”
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.last_face_box = None
        self.face_lost_count = 0
        self.face_keep_frames = 10  # 30í”„ë ˆì„ ê°„ê²©ì— ë§ê²Œ ì¦ê°€

        # ğŸ”¥ 30í”„ë ˆì„ ê°„ê²©ì— ìµœì í™”ëœ ì˜ˆì¸¡ ì•ˆì •í™”
        self.pred_buffer = deque(maxlen=2)  # 2ê°œ ê²°ê³¼ë§Œ ë³´ê´€

        # ğŸ”¥ ì§ì‚¬ê°í˜• ì§‘ì¤‘ ì˜ì—­ íŒŒë¼ë¯¸í„°ë¡œ ë³€ê²½
        self.attention_zone_width = 720    # ê°€ë¡œ 720í”½ì…€ (ê¸°ì¡´ ì› ì§€ë¦„ 360ì˜ 2ë°°)
        self.attention_zone_height = 180   # ì„¸ë¡œ 180í”½ì…€ (ê¸°ì¡´ ì› ë°˜ì§€ë¦„ê³¼ ë™ì¼)
        self.fixation_threshold = 4         
        self.head_angle_threshold = 20      
        self.stability_weight = 0.68

        # ğŸ”¥ ì§‘ì¤‘ íƒì§€ ì„ê³„ê°’ë“¤ (ê· í˜•ì¡íŒ ì¡°ì •)
        self.focus_sensitivity = {
            'central_focus_threshold': 0.7,     # ì¤‘ì•™ ì‘ì‹œ 40%
            'gaze_fixation_threshold': 0.7,     # ê³ ì • ì‘ì‹œ 60%
            'attention_score_threshold': 0.5,   # ì¢…í•© ì ìˆ˜ 50%
            'model_confidence_threshold': 0.25, # ëª¨ë¸ í™•ë¥  25%
            'focus_indicator_threshold': 3      # 7ì  ì¤‘ 3ì 
        }

        # ì‹œê³„ì—´ ë°ì´í„° ì¶”ì  (30í”„ë ˆì„ ê°„ê²©ì— ë§ê²Œ ì¡°ì •)
        self._gaze_history = deque(maxlen=10)  # 15 â†’ 10ìœ¼ë¡œ ì¡°ì •
        self._fixation_frames = 0
        self._stability_score = 0.5

        # ğŸ”¥ 30í”„ë ˆì„ ê°„ê²©ìš© ë¡œê¹…
        self.last_log_t = 0
        self.log_interval = 1.0  # 1ì´ˆë§ˆë‹¤ ë¡œê¹…

        # ğŸ”¥ 30í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.analysis_results = []

        print("âœ… 30í”„ë ˆì„ ê°„ê²© ì§‘ì¤‘ë„ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print("ğŸ“š ë°±ì—”ë“œ 10ì´ˆ ë°ì´í„° ìµœì í™”")
        print("ğŸ¯ 30í”„ë ˆì„ë‹¹ 0/1 ì¶œë ¥ ëª¨ë“œ")

    def detect_face(self, frame):
        """ì–¼êµ´ ê²€ì¶œ (ì˜¤íƒì§€ ë°©ì§€ ê°•í™”)"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.equalizeHist(gray)

        # ğŸ”¥ ì˜¤íƒì§€ ë°©ì§€ë¥¼ ìœ„í•œ ì—„ê²©í•œ ì„¤ì •
        faces = self.face_cascade.detectMultiScale(
            gray, 
            scaleFactor=1.08,     # ë” ì—„ê²©í•˜ê²Œ
            minNeighbors=6,       # ë” ë§ì€ ì´ì›ƒ í•„ìš”
            minSize=(100, 100),   # ë” í° ìµœì†Œ í¬ê¸°
            maxSize=(350, 350),   # ë” ì‘ì€ ìµœëŒ€ í¬ê¸°
            flags=cv2.CASCADE_SCALE_IMAGE
        )

        if len(faces):
            largest_face = max(faces, key=lambda b: b[2]*b[3])
            x, y, w, h = largest_face
            
            # ğŸ”¥ ê°„ë‹¨í•œ ê²€ì¦: í™”ë©´ ì¤‘ì•™ ê·¼ì²˜ì— ìˆê³ , ì ì • í¬ê¸°ì¸ê°€?
            frame_center_x, frame_center_y = frame.shape[1]//2, frame.shape[0]//2
            face_center_x, face_center_y = x + w//2, y + h//2
            
            distance = np.sqrt((face_center_x - frame_center_x)**2 + 
                              (face_center_y - frame_center_y)**2)
            
            # í™”ë©´ ì¤‘ì•™ì—ì„œ 400í”½ì…€ ì´ë‚´ + ì ì • í¬ê¸°ì¼ ë•Œë§Œ ì–¼êµ´ë¡œ ì¸ì •
            if distance < 400 and 100 <= w <= 350 and 100 <= h <= 350:
                self.last_face_box = largest_face
                self.face_lost_count = 0
                return self.last_face_box, True
            else:
                print("âš ï¸ ë°°ê²½ ì˜¤íƒì§€ ë°©ì§€: ì–¼êµ´ì´ ì•„ë‹Œ ê²ƒìœ¼ë¡œ íŒë‹¨")
        
        # ê¸°ì¡´ ì–¼êµ´ ì¶”ì  ë¡œì§ (30í”„ë ˆì„ ê°„ê²©ì— ë§ê²Œ ë” ì˜¤ë˜ ìœ ì§€)
        self.face_lost_count += 1
        if self.last_face_box is not None and self.face_lost_count < self.face_keep_frames:
            return self.last_face_box, False
        self.last_face_box = None
        return None, False

    def calculate_attention_features(self, face_box, frame_shape):
        """ë…¼ë¬¸ ê¸°ë°˜ ì§‘ì¤‘ë„ íŠ¹ì§• ê³„ì‚° (ì§ì‚¬ê°í˜• ì§‘ì¤‘ ì˜ì—­ ê¸°ë°˜)"""
        if face_box is None:
            return {
                'head_stability': 0.2,
                'gaze_fixation': 0.1,
                'central_focus': 0.0,
                'face_orientation': 0.0,
                'attention_score': 0.15
            }

        x, y, w, h = face_box
        
        # ê¸°ì¡´: ì–¼êµ´ ì¤‘ì‹¬ì  ì‚¬ìš©
        cx, cy = x + w/2, y + h/2  # ê³ ì • ì‘ì‹œ ë“± ê¸°ì¡´ ê³„ì‚°ìš©
        
        # ëˆˆ ìœ„ì¹˜ ì¶”ì • (í•´ë¶€í•™ì  ë¹„ìœ¨ ì‚¬ìš©)
        eye_center_x = x + w/2                # ì–¼êµ´ ì¤‘ì•™ X (ì¢Œìš° ëˆˆì˜ ì¤‘ì )
        eye_center_y = y + h * 0.35          # ì–¼êµ´ ìƒë‹¨ì—ì„œ 35% ì§€ì  (ëˆˆ ë†’ì´)
        
        screen_cx, screen_cy = frame_shape[1]//2, frame_shape[0]//2

        # 1. ğŸ”¥ Central Focus Score (ì§ì‚¬ê°í˜• ì˜ì—­ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •)
        # í™”ë©´ ì¤‘ì•™ì˜ ì§ì‚¬ê°í˜• ì˜ì—­ ì •ì˜
        rect_left = screen_cx - self.attention_zone_width // 2
        rect_right = screen_cx + self.attention_zone_width // 2
        rect_top = screen_cy - self.attention_zone_height // 2
        rect_bottom = screen_cy + self.attention_zone_height // 2
        
        # ëˆˆ ìœ„ì¹˜ê°€ ì§ì‚¬ê°í˜• ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
        if (rect_left <= eye_center_x <= rect_right and 
            rect_top <= eye_center_y <= rect_bottom):
            # ì§ì‚¬ê°í˜• ì•ˆì— ìˆìœ¼ë©´ ì¤‘ì‹¬ì—ì„œì˜ ê±°ë¦¬ì— ë”°ë¼ ì ìˆ˜ ê³„ì‚°
            # Xì¶• ê±°ë¦¬ (ê°€ë¡œ ë°©í–¥)
            x_distance = abs(eye_center_x - screen_cx) / (self.attention_zone_width / 2)
            # Yì¶• ê±°ë¦¬ (ì„¸ë¡œ ë°©í–¥) 
            y_distance = abs(eye_center_y - screen_cy) / (self.attention_zone_height / 2)
            
            # ì§ì‚¬ê°í˜• ì¤‘ì‹¬ì—ì„œ ë©€ìˆ˜ë¡ ì ìˆ˜ ê°ì†Œ
            central_focus = max(0, 1 - max(x_distance, y_distance))
        else:
            # ì§ì‚¬ê°í˜• ë°–ì— ìˆìœ¼ë©´ 0ì 
            central_focus = 0.0

        # 2. Head Orientation Score (ê¸°ì¡´ ì–¼êµ´ ì¤‘ì‹¬ ê¸°ì¤€ ìœ ì§€)
        angle_deviation = abs(math.atan2(cy - screen_cy, cx - screen_cx) * 180 / math.pi)
        face_orientation = max(0, 1 - angle_deviation / self.head_angle_threshold)

        # 3. Gaze Fixation (ê¸°ì¡´ ì–¼êµ´ ì¤‘ì‹¬ ê¸°ì¤€ ìœ ì§€)
        self._gaze_history.append((cx, cy))
        
        if len(self._gaze_history) >= 2:
            recent_movement = 0
            for i in range(1, min(3, len(self._gaze_history))):
                prev_x, prev_y = self._gaze_history[-i-1]
                curr_x, curr_y = self._gaze_history[-i]
                movement = np.sqrt((curr_x - prev_x)**2 + (curr_y - prev_y)**2)
                recent_movement += movement

            # ê³ ì • ì‘ì‹œ íŒë‹¨
            if recent_movement < 50:
                self._fixation_frames += 1
            else:
                self._fixation_frames = max(0, self._fixation_frames - 1)

            gaze_fixation = min(1.0, self._fixation_frames / self.fixation_threshold)
        else:
            gaze_fixation = 0.0

        # 4. Head Stability (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
        face_size_consistency = min(1.0, (w * h) / 15000)
        head_stability = (face_orientation + face_size_consistency) / 2

        # 5. ì§ì‚¬ê°í˜• ê¸°ë°˜ ì •ë°€ ì§‘ì¤‘ë„ ì¶”ê°€ ê²€ì¦
        if central_focus > 0.8:  # ì§ì‚¬ê°í˜• ì¤‘ì•™ì— ê°€ê¹Œìš¸ ë•Œ
            rectangular_precision_bonus = 0.1
        else:
            rectangular_precision_bonus = 0.0

        # 6. ì¢…í•© Attention Score (ì§ì‚¬ê°í˜• ê¸°ë°˜ central_focus ë°˜ì˜)
        attention_score = (
            central_focus * 0.4 +                    # ğŸ”¥ ì§ì‚¬ê°í˜• ì˜ì—­ ê¸°ë°˜ ì¤‘ì•™ ì§‘ì¤‘
            gaze_fixation * 0.3 +                    
            head_stability * self.stability_weight * 0.2 +
            face_orientation * 0.1 +                 
            rectangular_precision_bonus              # ğŸ”¥ ì§ì‚¬ê°í˜• ì •ë°€ë„ ë³´ë„ˆìŠ¤
        )

        # 30í”„ë ˆì„ ê°„ê²©ì— ë§ëŠ” ì•ˆì •ì ì¸ ìŠ¤ë¬´ë”©
        self._stability_score = 0.7 * self._stability_score + 0.3 * attention_score

        return {
            'head_stability': head_stability,
            'gaze_fixation': gaze_fixation,
            'central_focus': central_focus,          # ğŸ”¥ ì´ì œ ì§ì‚¬ê°í˜• ì˜ì—­ ê¸°ë°˜ ê°’
            'face_orientation': face_orientation,
            'attention_score': self._stability_score
        }



    def build_research_based_features(self, frame, face_box):
        """ì—°êµ¬ ê¸°ë°˜ íŠ¹ì§• ë²¡í„° ìƒì„±"""
        vec = np.zeros(26, dtype=np.float32)
        attention_features = self.calculate_attention_features(face_box, frame.shape)

        if face_box is not None:
            x, y, w, h = face_box
            cx, cy = x + w/2, y + h/2

            attention_score = attention_features['attention_score']
            
            if attention_score > 0.5:
                # ê³ ì§‘ì¤‘ íŠ¹ì§•
                vec[0:3] = [0.0, 0.0, 0.0]
                vec[4] = 640; vec[5] = 360
                vec[13:15] = [0.5, 0.5]
                vec[15] = 0.95; vec[16] = 0.9
                vec[17] = 5.0; vec[18] = 0.02
                vec[19] = min(20, self._fixation_frames)
                vec[21] = attention_features['central_focus']
                
            elif attention_score > 0.25:
                # ë³´í†µì§‘ì¤‘ íŠ¹ì§•
                vec[0:3] = [0.5, 0.5, 0.2]
                vec[4] = cx; vec[5] = cy
                vec[13:15] = [1.5, 1.5]
                vec[15] = 0.8; vec[16] = 0.8
                vec[17] = 15.0; vec[18] = 0.05
                vec[19] = min(15, self._fixation_frames)
                vec[21] = attention_features['central_focus'] * 0.8
                
            else:
                # ì €ì§‘ì¤‘ íŠ¹ì§•
                vec[0:3] = [3.0, 2.5, 2.0]
                vec[4] = cx + np.random.normal(0, 50)
                vec[5] = cy + np.random.normal(0, 50)
                vec[13:15] = [4.0, 3.5]
                vec[15] = 0.3; vec[16] = 0.4
                vec[17] = 50.0; vec[18] = 0.4
                vec[19] = max(2, self._fixation_frames)
                vec[21] = attention_features['central_focus'] * 0.3

            # ê³µí†µ íŠ¹ì§•
            vec[3] = min(100, 90000 / max(w*h, 1000) + 45)
            vec[6:10] = [cx-20, cy-10, cx+20, cy-10]
            vec[10:12] = [0.3, 0.3]
            vec[12] = abs((cy - 360) / 360) * 5
            vec[20] = attention_features['gaze_fixation'] * 10
            vec[22] = min(0.8, attention_features['head_stability'])

        return vec, attention_features

    def focus_sensitive_prediction(self, feat_vec, attention_features):
        """ğŸ”¥ 30í”„ë ˆì„ ìµœì í™”ëœ ì§‘ì¤‘ íƒì§€ ì˜ˆì¸¡"""
        
        # 1ë‹¨ê³„: ê¸°ë³¸ 3í´ë˜ìŠ¤ ëª¨ë¸ ì˜ˆì¸¡
        raw_pred, probs = self.classifier.predict(feat_vec.reshape(1, -1))
        raw_cls = raw_pred[0]
        
        # 2ë‹¨ê³„: ì§‘ì¤‘ ì§€í‘œ ì ìˆ˜ ê³„ì‚°
        focus_indicators = 0
        sensitivity = self.focus_sensitivity
        
        # ğŸ”¥ ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡ì— í›¨ì”¬ ë” ë†’ì€ ê°€ì¤‘ì¹˜
        if raw_cls == 2:  # ì§‘ì¤‘ ì˜ˆì¸¡
            focus_indicators += 4  # ê¸°ì¡´ 3 â†’ 4
        elif raw_cls == 0:  # ğŸ”¥ ë¹„ì§‘ì¤‘ ì˜ˆì¸¡ ì‹œ ê°•í•œ í˜ë„í‹° ì¶”ê°€
            focus_indicators -= 4  # ìƒˆë¡œ ì¶”ê°€: ë¹„ì§‘ì¤‘ì´ë©´ -4ì 
        elif probs[0][2] > sensitivity['model_confidence_threshold']:
            focus_indicators += 2
        
        # ğŸ”¥ ì›ë³¸ ëª¨ë¸ì´ í™•ì‹ í•  ë•Œ ì¶”ê°€ í˜ë„í‹°/ë³´ë„ˆìŠ¤
        if probs[0][0] > 0.8:  # ë¹„ì§‘ì¤‘ í™•ë¥  80% ì´ìƒ
            focus_indicators -= 3  # ì¶”ê°€ í˜ë„í‹°
        elif probs[0][2] > 0.8:  # ì§‘ì¤‘ í™•ë¥  80% ì´ìƒ
            focus_indicators += 3  # ì¶”ê°€ ë³´ë„ˆìŠ¤
        
        # ë…¼ë¬¸ ê¸°ë°˜ ì§€í‘œë“¤
        if attention_features['central_focus'] > sensitivity['central_focus_threshold']:
            focus_indicators += 2
            
        if attention_features['gaze_fixation'] > sensitivity['gaze_fixation_threshold']:
            focus_indicators += 2
            
        if attention_features['attention_score'] > sensitivity['attention_score_threshold']:
            focus_indicators += 2
        
        # ì¶”ê°€ ì¡°ê±´ë“¤
        if attention_features['head_stability'] > 0.4:
            focus_indicators += 1
            
        if attention_features['face_orientation'] > 0.3:
            focus_indicators += 1
        
        # 3ë‹¨ê³„: ì§‘ì¤‘ íŒì •
        if focus_indicators >= sensitivity['focus_indicator_threshold']:
            binary_result = 1  # ì§‘ì¤‘
            confidence = min(0.95, 0.6 + 
                           attention_features['attention_score'] * 0.2 + 
                           probs[0][2] * 0.15)
        else:
            binary_result = 0  # ì§‘ì¤‘ì•ˆí•¨
            confidence = max(0.5, (probs[0][0] + probs[0][1]) / 2)
        
        # ğŸ”¥ 4ë‹¨ê³„: 30í”„ë ˆì„ ê°„ê²©ìš© ì‹œê°„ì  ì•ˆì •í™”
        self.pred_buffer.append(binary_result)
        
        if len(self.pred_buffer) >= 2:
            # ì§‘ì¤‘ ìš°í˜¸ì  ë‹¤ìˆ˜ê²° (2ê°œ ì¤‘ 1ê°œë§Œ ì§‘ì¤‘ì´ì–´ë„ ì§‘ì¤‘ìœ¼ë¡œ)
            focus_count = sum(1 for x in self.pred_buffer if x == 1)
            if focus_count >= 1:
                final_result = 1
            else:
                final_result = 0
        else:
            final_result = binary_result
        
        return raw_cls, final_result, probs[0], confidence

    def log_detailed_analysis(self, frame_idx, face_status, attention_features, raw_cls, final_cls, conf, probs):
        """30í”„ë ˆì„ ê°„ê²©ìš© ìƒì„¸ ë¡œê·¸"""
        now = time.time()
        if now - self.last_log_t < self.log_interval:
            return
        self.last_log_t = now

        if face_status == 'miss':
            print(f"[Frame {frame_idx:4d}] âŒ ì–¼êµ´ ì—†ìŒ â†’ ê²°ê³¼: 0 (ë¹„ì§‘ì¤‘)")
            return

        status_icon = "ğŸ¯" if face_status == 'detect' else "ğŸ“"
        raw_name = "Focused" if raw_cls == 2 else "Not Focused" if raw_cls == 0 else "Distracted"
        final_name = self.cls_name[final_cls] if final_cls is not None else "None"
        
        # ğŸ”¥ 30í”„ë ˆì„ ê²°ê³¼ ê°•ì¡° ë¡œê¹…
        print(f"\n{'='*80}")
        print(f"[Frame {frame_idx:4d}] ğŸ“Š 30í”„ë ˆì„ ë¶„ì„ ê²°ê³¼: {final_cls} ({'ì§‘ì¤‘' if final_cls == 1 else 'ë¹„ì§‘ì¤‘'})")
        print(f"{'='*80}")
        print(f"{status_icon} Raw: {raw_name:12s} â†’ Final: {final_name:12s} (í™•ì‹ ë„: {conf:.3f})")
        print(f"ğŸ“Š ì›ë³¸ í™•ë¥ : [ ë¹„ì§‘ì¤‘:{probs[0]:.2f}  ì£¼ì˜ì‚°ë§Œ:{probs[1]:.2f}  ì§‘ì¤‘:{probs[2]:.2f} ]")
        
        # ë…¼ë¬¸ ê¸°ë°˜ ë¶„ì„ ì§€í‘œ
        att = attention_features
        print(f"ğŸ¯ ì§€í‘œ ë¶„ì„:")
        print(f"   - ì¢…í•© ì ìˆ˜: {att['attention_score']:.2f}")
        print(f"   - ì¤‘ì•™ ì§‘ì¤‘: {att['central_focus']:.2f}")
        print(f"   - ê³ ì • ì‘ì‹œ: {att['gaze_fixation']:.2f}")
        print(f"   - ë¨¸ë¦¬ ì•ˆì •ì„±: {att['head_stability']:.2f}")
        print(f"{'='*80}\n")

    def draw_binary_ui(self, frame, face_box, face_status, binary_cls, conf, attention_features):
        """30í”„ë ˆì„ ë¶„ì„ìš© UI (ì§ì‚¬ê°í˜• ì§‘ì¤‘ ì˜ì—­ í‘œì‹œ)"""
        overlay = frame.copy()
        cv2.rectangle(overlay, (20, 20), (550, 320), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.4, frame, 0.6, 0, frame)

        # ì–¼êµ´ ë°•ìŠ¤
        if face_box is not None:
            x, y, w, h = face_box
            
            if binary_cls == 1:
                box_color = (0, 255, 0)  # ì´ˆë¡: ì§‘ì¤‘
            else:
                box_color = (0, 0, 255)  # ë¹¨ê°•: ì§‘ì¤‘ì•ˆí•¨
                
            cv2.rectangle(frame, (x-3, y-3), (x+w+3, y+h+3), box_color, 3)
            
            # ğŸ”¥ ì§ì‚¬ê°í˜• ì§‘ì¤‘ ì˜ì—­ í‘œì‹œ (ê¸°ì¡´ ì› ëŒ€ì‹ )
            center_x, center_y = frame.shape[1]//2, frame.shape[0]//2
            
            # ì§ì‚¬ê°í˜• ì¢Œí‘œ ê³„ì‚°
            rect_left = center_x - self.attention_zone_width // 2
            rect_right = center_x + self.attention_zone_width // 2
            rect_top = center_y - self.attention_zone_height // 2
            rect_bottom = center_y + self.attention_zone_height // 2
            
            # ì§ì‚¬ê°í˜• ê·¸ë¦¬ê¸° (í°ìƒ‰ í…Œë‘ë¦¬)
            cv2.rectangle(frame, (rect_left, rect_top), (rect_right, rect_bottom), (255, 255, 255), 2)

        # 30í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        if binary_cls is not None:
            state_text = "FOCUSED" if binary_cls == 1 else "NOT FOCUSED"
            color = self.cls_color[binary_cls]
            
            cv2.putText(frame, f"State: {state_text}", (40, 70), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, 3)
            cv2.putText(frame, f"Confidence: {conf:.3f}", (40, 110), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

        # ë…¼ë¬¸ ê¸°ë°˜ ì§€í‘œ
        att = attention_features
        cv2.putText(frame, f"Attention Score: {att['attention_score']:.2f}", (40, 150), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(frame, f"Central Focus: {att['central_focus']:.2f}", (40, 180), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        cv2.putText(frame, f"Gaze Fixation: {att['gaze_fixation']:.2f}", (40, 210), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # 30í”„ë ˆì„ ë¶„ì„ ëª¨ë“œ í‘œì‹œ
        cv2.putText(frame, "Mode: 30-Frame Analysis (Rectangular Focus Zone)", (40, 240), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (128, 255, 128), 1)
        cv2.putText(frame, f"Focus Area: {self.attention_zone_width}x{self.attention_zone_height} pixels", (40, 260), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 128), 1)
        cv2.putText(frame, "Research: Zhang(2019), Duchowski(2018), Kim(2020)", (40, 280), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (128, 128, 128), 1)

        return frame


    def run(self):
        """30í”„ë ˆì„ ê°„ê²© ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

        if not cap.isOpened():
            print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return

        # ì´ˆê¸°í™”
        self._gaze_history = deque(maxlen=10)
        self._fixation_frames = 0

        f_idx, proc_cnt = 0, 0
        t0 = time.time()

        # ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
        face_status = 'miss'
        binary_cls = None
        conf = 0.0
        attention_features = {
            'attention_score': 0.0, 
            'central_focus': 0.0,
            'gaze_fixation': 0.0, 
            'head_stability': 0.0
        }

        print("ğŸš€ 30í”„ë ˆì„ ê°„ê²© ì§‘ì¤‘ë„ ë¶„ì„ ì‹œì‘")
        print("ğŸ“š ë°±ì—”ë“œ 10ì´ˆ ë°ì´í„°ì— ìµœì í™”")
        print("ğŸ¯ 30í”„ë ˆì„ë§ˆë‹¤ 0/1 ì¶œë ¥")
        print("â±ï¸  ì´ˆë‹¹ 1íšŒ ë¶„ì„ (30fps â†’ 1fps)")
        print("ESC/Që¡œ ì¢…ë£Œ\n")

        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            f_idx += 1

            # ğŸ”¥ 30í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬ (ì´ˆë‹¹ 1íšŒ)
            if f_idx % 30 == 0:
                proc_cnt += 1
                face_detection_result = self.detect_face(frame)
                
                if face_detection_result[0] is not None:
                    face_box, is_detect = face_detection_result
                else:
                    face_box, is_detect = None, False
                
                if is_detect:
                    face_status = 'detect'
                elif face_box is not None:
                    face_status = 'track'
                else:
                    face_status = 'miss'

                if face_box is not None:
                    try:
                        feat_vec, attention_features = self.build_research_based_features(frame, face_box)
                        raw_cls, binary_cls, probs, conf = self.focus_sensitive_prediction(feat_vec, attention_features)
                        
                        # ğŸ”¥ 30í”„ë ˆì„ ê²°ê³¼ ì €ì¥ ë° ë¡œê¹…
                        result = {
                            'frame': f_idx,
                            'timestamp': time.time(),
                            'result': binary_cls,
                            'confidence': conf
                        }
                        self.analysis_results.append(result)
                        
                        self.log_detailed_analysis(f_idx, face_status, attention_features, raw_cls, binary_cls, conf, probs)
                        
                    except Exception as e:
                        print(f"âŒ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
                        binary_cls = 0  # ì˜¤ë¥˜ ì‹œ ë¹„ì§‘ì¤‘
                        conf = 0.0
                        
                        # ì˜¤ë¥˜ ê²°ê³¼ë„ ì €ì¥
                        result = {
                            'frame': f_idx,
                            'timestamp': time.time(),
                            'result': 0,
                            'confidence': 0.0
                        }
                        self.analysis_results.append(result)
                else:
                    binary_cls = 0  # ì–¼êµ´ ì—†ìŒ ì‹œ ë¹„ì§‘ì¤‘
                    conf = 0.0
                    
                    # ì–¼êµ´ ì—†ìŒ ê²°ê³¼ ì €ì¥
                    result = {
                        'frame': f_idx,
                        'timestamp': time.time(),
                        'result': 0,
                        'confidence': 0.0
                    }
                    self.analysis_results.append(result)
                    
                    print(f"\n[Frame {f_idx:4d}] âŒ ì–¼êµ´ ì—†ìŒ â†’ ê²°ê³¼: 0 (ë¹„ì§‘ì¤‘)\n")

            # UI ì—…ë°ì´íŠ¸ (ë§¤ í”„ë ˆì„)
            current_face_box = self.last_face_box
            frame = self.draw_binary_ui(frame, current_face_box, face_status, binary_cls, conf, attention_features)

            # ğŸ”¥ 30í”„ë ˆì„ ì§„í–‰ ìƒí™© í‘œì‹œ
            elapsed = time.time() - t0
            fps = f_idx / elapsed if elapsed > 0 else 0
            next_analysis = 30 - (f_idx % 30)
            
            cv2.putText(frame, f"FPS: {fps:4.1f} | Analysis: {proc_cnt}", (1020, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(frame, f"Next in: {next_analysis} frames", (1020, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

            cv2.imshow("30-Frame Concentration Analysis", frame)
            key = cv2.waitKey(1) & 0xFF
            if key in (27, ord('q')):
                break

        # ğŸ”¥ ì¢…ë£Œ ì‹œ ê²°ê³¼ ìš”ì•½
        dur = time.time() - t0
        print(f"\n{'='*80}")
        print(f"ğŸ“Š 30í”„ë ˆì„ ë¶„ì„ ì™„ë£Œ")
        print(f"{'='*80}")
        print(f"ì´ í”„ë ˆì„: {f_idx} | ë¶„ì„ íšŸìˆ˜: {proc_cnt} | í‰ê·  FPS: {f_idx/dur:.1f}")
        print(f"ë¶„ì„ ê°„ê²©: 30í”„ë ˆì„ (ì´ˆë‹¹ 1íšŒ)")
        print(f"ì´ ë¶„ì„ ê²°ê³¼: {len(self.analysis_results)}ê°œ")
        
        if self.analysis_results:
            focus_count = sum(1 for r in self.analysis_results if r['result'] == 1)
            focus_ratio = focus_count / len(self.analysis_results) * 100
            print(f"ì§‘ì¤‘ íŒì •: {focus_count}/{len(self.analysis_results)} ({focus_ratio:.1f}%)")
        
        print(f"{'='*80}")
        
        cap.release()
        cv2.destroyAllWindows()

    def get_latest_result(self):
        """ë°±ì—”ë“œ ì—°ë™ìš©: ìµœì‹  ë¶„ì„ ê²°ê³¼ ë°˜í™˜"""
        if self.analysis_results:
            return self.analysis_results[-1]
        return None

    def get_results_summary(self, last_n=10):
        """ë°±ì—”ë“œ ì—°ë™ìš©: ìµœê·¼ Nê°œ ê²°ê³¼ ìš”ì•½"""
        if not self.analysis_results:
            return None
            
        recent_results = self.analysis_results[-last_n:]
        focus_count = sum(1 for r in recent_results if r['result'] == 1)
        
        return {
            'total_analyzed': len(recent_results),
            'focus_count': focus_count,
            'focus_ratio': focus_count / len(recent_results) if recent_results else 0,
            'latest_result': recent_results[-1] if recent_results else None
        }


def main():
    model_path = input("ëª¨ë¸ ê²½ë¡œ (Enter=ê¸°ë³¸ê°’): ").strip() or \
                 "./json_features_3class_concentration_classifier.pkl"
    
    if not os.path.exists(model_path):
        print("âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ")
        return
    
    try:
        ConcentrationInference(model_path).run()
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
