#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ëª¨ë¸ í•™ìŠµ ê¸°ì¤€ ë° ì§‘ì¤‘ë„ íŒë‹¨ íŒ¨í„´ ë¶„ì„ ë„êµ¬
"""

import pandas as pd
import numpy as np
import os
import sys
from ml_classifier import ConcentrationClassifier
import joblib

def check_file_exists(filepath):
    """íŒŒì¼ ì¡´ì¬ í™•ì¸"""
    if not os.path.exists(filepath):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filepath}")
        return False
    return True

def analyze_dataset_patterns():
    """í•™ìŠµ ë°ì´í„°ì˜ í´ë˜ìŠ¤ë³„ íŒ¨í„´ ë¶„ì„"""
    csv_path = "./processed_data/json_features_3class_dataset.csv"
    
    if not check_file_exists(csv_path):
        print("ğŸ’¡ ë¨¼ì € data_processor.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.")
        return
    
    print("=== ğŸ“Š í•™ìŠµ ë°ì´í„° íŒ¨í„´ ë¶„ì„ ===")
    print("=" * 60)
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(csv_path)
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(df)}ê°œ")
    
    # í´ë˜ìŠ¤ ë¶„í¬
    print(f"\nğŸ“ˆ í´ë˜ìŠ¤ ë¶„í¬:")
    class_names = {0: 'ë¹„ì§‘ì¤‘', 1: 'ì£¼ì˜ì‚°ë§Œ', 2: 'ì§‘ì¤‘'}
    for class_id in [0, 1, 2]:
        count = len(df[df['label_3class'] == class_id])
        percentage = count / len(df) * 100
        print(f"  {class_names[class_id]}: {count}ê°œ ({percentage:.1f}%)")
    
    # í•µì‹¬ íŠ¹ì§•ë³„ í´ë˜ìŠ¤ íŒ¨í„´ ë¶„ì„
    key_features = [
        'gaze_jitter',           # ì‹œì„  ë–¨ë¦¼ (ì¤‘ìš”ë„ 1ìœ„)
        'saccade_frequency',     # ê¸‰ì† ì•ˆêµ¬ìš´ë™ (ì¤‘ìš”ë„ 2ìœ„)
        'head_pitch_std',        # ë¨¸ë¦¬ ì›€ì§ì„ ë³€ë™ì„± (ì¤‘ìš”ë„ 3ìœ„)
        'gaze_y_mean',           # ì‹œì„  Yì¢Œí‘œ (ì¤‘ìš”ë„ 4ìœ„)
        'l_EAR_mean',            # ëˆˆ ê¹œë¹¡ì„ (ì¤‘ìš”ë„ 5ìœ„)
        'gaze_stability',        # ì‹œì„  ì•ˆì •ì„±
        'head_stability',        # ë¨¸ë¦¬ ì•ˆì •ì„±
        'fixation_duration',     # ê³ ì • ì‘ì‹œ ì‹œê°„
        'gaze_direction_prob'    # ì •ë©´ ì‘ì‹œ í™•ë¥ 
    ]
    
    print(f"\nğŸ¯ í•µì‹¬ íŠ¹ì§•ë³„ í´ë˜ìŠ¤ íŒ¨í„´:")
    print("=" * 60)
    
    for feature in key_features:
        if feature not in df.columns:
            print(f"âŒ {feature}: ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
            continue
            
        print(f"\nğŸ“Œ {feature}:")
        print("-" * 40)
        
        for class_id in [0, 1, 2]:
            class_data = df[df['label_3class'] == class_id][feature]
            if len(class_data) > 0:
                mean_val = class_data.mean()
                std_val = class_data.std()
                min_val = class_data.min()
                max_val = class_data.max()
                median_val = class_data.median()
                
                print(f"  {class_names[class_id]:>6}: í‰ê· ={mean_val:6.3f} | "
                      f"í‘œì¤€í¸ì°¨={std_val:6.3f} | ì¤‘ì•™ê°’={median_val:6.3f} | "
                      f"ë²”ìœ„=[{min_val:6.3f}, {max_val:6.3f}]")
    
    # ì§‘ì¤‘ë„ íŒë‹¨ ì„ê³„ê°’ ì¶”ë¡ 
    print(f"\nğŸ” ì§‘ì¤‘ë„ íŒë‹¨ ì„ê³„ê°’ ì¶”ë¡ :")
    print("=" * 60)
    
    focused_data = df[df['label_3class'] == 2]  # ì§‘ì¤‘ í´ë˜ìŠ¤
    distracted_data = df[df['label_3class'] == 1]  # ì£¼ì˜ì‚°ë§Œ í´ë˜ìŠ¤
    unfocused_data = df[df['label_3class'] == 0]  # ë¹„ì§‘ì¤‘ í´ë˜ìŠ¤
    
    print("ğŸ“Š ëª¨ë¸ì´ í•™ìŠµí•œ ì§‘ì¤‘ ìƒíƒœì˜ íŠ¹ì§•:")
    print("-" * 40)
    
    concentration_thresholds = {}
    
    for feature in key_features[:6]:  # ìƒìœ„ 6ê°œ íŠ¹ì§•ë§Œ
        if feature in df.columns:
            focused_mean = focused_data[feature].mean()
            distracted_mean = distracted_data[feature].mean()
            unfocused_mean = unfocused_data[feature].mean()
            
            # ì§‘ì¤‘ í´ë˜ìŠ¤ê°€ ë‹¤ë¥¸ í´ë˜ìŠ¤ë“¤ê³¼ êµ¬ë³„ë˜ëŠ” ë°©í–¥ íŒŒì•…
            if focused_mean > max(distracted_mean, unfocused_mean):
                threshold = (focused_mean + max(distracted_mean, unfocused_mean)) / 2
                direction = "ë†’ì„ìˆ˜ë¡"
            else:
                threshold = (focused_mean + min(distracted_mean, unfocused_mean)) / 2
                direction = "ë‚®ì„ìˆ˜ë¡"
            
            concentration_thresholds[feature] = {
                'threshold': threshold,
                'direction': direction,
                'focused_avg': focused_mean
            }
            
            print(f"  {feature:20}: {direction} ì§‘ì¤‘ (ì„ê³„ê°’: {threshold:.3f}, ì§‘ì¤‘í‰ê· : {focused_mean:.3f})")
    
    return concentration_thresholds

def analyze_model_importance():
    """XGBoost ëª¨ë¸ì˜ íŠ¹ì§• ì¤‘ìš”ë„ ë¶„ì„"""
    model_path = "./xgboost_3class_concentration_classifier.pkl"
    
    if not check_file_exists(model_path):
        print("ğŸ’¡ ë¨¼ì € train_model.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ì„¸ìš”.")
        return
    
    print(f"\n=== ğŸ¤– XGBoost ëª¨ë¸ íŠ¹ì§• ì¤‘ìš”ë„ ë¶„ì„ ===")
    print("=" * 60)
    
    try:
        # ëª¨ë¸ ë¡œë“œ
        model_data = joblib.load(model_path)
        model = model_data['model']
        feature_columns = model_data['feature_columns']
        
        # íŠ¹ì§• ì¤‘ìš”ë„ ì¶”ì¶œ
        if hasattr(model, 'feature_importances_'):
            importances = model.feature_importances_
            
            # ì¤‘ìš”ë„ë³„ ì •ë ¬
            feature_importance = list(zip(feature_columns, importances))
            feature_importance.sort(key=lambda x: x[1], reverse=True)
            
            print("ğŸ“Š íŠ¹ì§• ì¤‘ìš”ë„ ìˆœìœ„ (ìƒìœ„ 15ê°œ):")
            print("-" * 50)
            for i, (feature, importance) in enumerate(feature_importance[:15]):
                percentage = importance * 100
                bar = "â–ˆ" * int(percentage / 2)  # ì‹œê°ì  ë°”
                print(f"{i+1:2d}. {feature:20s}: {importance:.4f} ({percentage:5.2f}%) {bar}")
            
            # ì§‘ì¤‘ë„ íŒë‹¨ì— í•µì‹¬ì ì¸ íŠ¹ì§•ë“¤ ë¶„ì„
            print(f"\nğŸ¯ ì§‘ì¤‘ë„ íŒë‹¨ í•µì‹¬ íŠ¹ì§• í•´ì„:")
            print("-" * 50)
            
            interpretations = {
                'gaze_jitter': 'ì‹œì„ ì´ ëœ ë–¨ë¦´ìˆ˜ë¡ ì§‘ì¤‘',
                'saccade_frequency': 'ê¸‰ì† ì•ˆêµ¬ìš´ë™ì´ ì ì„ìˆ˜ë¡ ì§‘ì¤‘',
                'head_pitch_std': 'ë¨¸ë¦¬ ì›€ì§ì„ì´ ì•ˆì •ì ì¼ìˆ˜ë¡ ì§‘ì¤‘',
                'gaze_y_mean': 'íŠ¹ì • Yì¢Œí‘œ(í™”ë©´ ì¤‘ì•™)ë¥¼ ë³¼ ë•Œ ì§‘ì¤‘',
                'l_EAR_mean': 'ì •ìƒì ì¸ ê¹œë¹¡ì„ íŒ¨í„´ì¼ ë•Œ ì§‘ì¤‘',
                'gaze_stability': 'ì‹œì„ ì´ ì•ˆì •ì ì¼ìˆ˜ë¡ ì§‘ì¤‘',
                'head_stability': 'ë¨¸ë¦¬ê°€ ì•ˆì •ì ì¼ìˆ˜ë¡ ì§‘ì¤‘',
                'fixation_duration': 'ì˜¤ë˜ ê³ ì •í•´ì„œ ë³¼ìˆ˜ë¡ ì§‘ì¤‘',
                'gaze_direction_prob': 'ì •ë©´ì„ ë³¼ìˆ˜ë¡ ì§‘ì¤‘'
            }
            
            for feature, importance in feature_importance[:10]:
                if feature in interpretations:
                    print(f"  â€¢ {feature:20}: {interpretations[feature]} (ì¤‘ìš”ë„: {importance:.3f})")
            
            return feature_importance
            
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def analyze_decision_boundaries():
    """ì‹¤ì œ ëª¨ë¸ì˜ ê²°ì • ê²½ê³„ ë¶„ì„"""
    csv_path = "./processed_data/json_features_3class_dataset.csv"
    model_path = "./xgboost_3class_concentration_classifier.pkl"
    
    if not check_file_exists(csv_path) or not check_file_exists(model_path):
        return
    
    print(f"\n=== ğŸ² ëª¨ë¸ ê²°ì • ê²½ê³„ ë¶„ì„ ===")
    print("=" * 60)
    
    try:
        # ë°ì´í„°ì™€ ëª¨ë¸ ë¡œë“œ
        df = pd.read_csv(csv_path)
        model_data = joblib.load(model_path)
        model = model_data['model']
        scaler = model_data['scaler']
        feature_columns = model_data['feature_columns']
        
        # íŠ¹ì§• ì¶”ì¶œ
        X = df[feature_columns].fillna(0).values
        y = df['label_3class'].values
        
        # ì •ê·œí™”
        X_scaled = scaler.transform(X)
        
        # ì˜ˆì¸¡ í™•ë¥ 
        probabilities = model.predict_proba(X_scaled)
        predictions = model.predict(X_scaled)
        
        # í´ë˜ìŠ¤ë³„ í‰ê·  í™•ì‹ ë„ ë¶„ì„
        print("ğŸ“Š í´ë˜ìŠ¤ë³„ ëª¨ë¸ í™•ì‹ ë„:")
        print("-" * 40)
        
        class_names = {0: 'ë¹„ì§‘ì¤‘', 1: 'ì£¼ì˜ì‚°ë§Œ', 2: 'ì§‘ì¤‘'}
        
        for class_id in [0, 1, 2]:
            class_indices = (y == class_id)
            class_probs = probabilities[class_indices]
            
            # í•´ë‹¹ í´ë˜ìŠ¤ë¡œ ì •í™•íˆ ì˜ˆì¸¡ëœ ê²½ìš°ì˜ í™•ì‹ ë„
            correct_predictions = (predictions[class_indices] == class_id)
            if np.any(correct_predictions):
                correct_probs = class_probs[correct_predictions]
                avg_confidence = np.mean(correct_probs[:, class_id])
                print(f"  {class_names[class_id]:>6}: í‰ê·  í™•ì‹ ë„ {avg_confidence:.3f}")
        
        # í˜¼ë™ë˜ê¸° ì‰¬ìš´ ê²½ê³„ ì‚¬ë¡€ ë¶„ì„
        print(f"\nğŸ¤” ëª¨ë¸ì´ í˜¼ë™í•˜ê¸° ì‰¬ìš´ ê²½ê³„ ì‚¬ë¡€:")
        print("-" * 50)
        
        for i in range(len(probabilities)):
            probs = probabilities[i]
            true_class = y[i]
            pred_class = predictions[i]
            
            # í™•ë¥ ì´ ë¹„ìŠ·í•œ ê²½ìš° (ë¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡)
            max_prob = np.max(probs)
            second_max_prob = np.sort(probs)[-2]
            
            if max_prob - second_max_prob < 0.2:  # ì°¨ì´ê°€ 0.2 ë¯¸ë§Œì¸ ì• ë§¤í•œ ê²½ìš°
                print(f"  ìƒ˜í”Œ {i}: ì‹¤ì œ={class_names[true_class]}, "
                      f"ì˜ˆì¸¡={class_names[pred_class]}, "
                      f"í™•ë¥ =[{probs[0]:.2f}, {probs[1]:.2f}, {probs[2]:.2f}]")
                
                # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
                if sum(1 for j in range(i) if probabilities[j].max() - np.sort(probabilities[j])[-2] < 0.2) >= 5:
                    break
        
    except Exception as e:
        print(f"âŒ ê²°ì • ê²½ê³„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

def generate_concentration_rules():
    """ì§‘ì¤‘ë„ íŒë‹¨ ê·œì¹™ ìƒì„±"""
    print(f"\n=== ğŸ“‹ ì‹¤ì‹œê°„ ì§‘ì¤‘ë„ íŒë‹¨ ê·œì¹™ ===")
    print("=" * 60)
    
    print("ğŸ¯ ëª¨ë¸ì´ í•™ìŠµí•œ ì§‘ì¤‘ ìƒíƒœ íŒë‹¨ ê¸°ì¤€:")
    print("-" * 50)
    
    rules = [
        "1. ì‹œì„  ë–¨ë¦¼(gaze_jitter) < 20 í”½ì…€",
        "2. ê¸‰ì† ì•ˆêµ¬ìš´ë™(saccade_frequency) < 0.1 íšŒ/í”„ë ˆì„",
        "3. ë¨¸ë¦¬ ì›€ì§ì„ ë³€ë™ì„±(head_pitch_std) < 2.0ë„",
        "4. ì‹œì„ ì´ í™”ë©´ ì¤‘ì•™ ê·¼ì²˜(gaze_y_mean â‰ˆ 540)",
        "5. ì •ìƒì ì¸ ê¹œë¹¡ì„ íŒ¨í„´(l_EAR_mean â‰ˆ 0.3)",
        "6. ë†’ì€ ì‹œì„  ì•ˆì •ì„±(gaze_stability > 0.7)",
        "7. ë†’ì€ ë¨¸ë¦¬ ì•ˆì •ì„±(head_stability > 0.7)",
        "8. ê¸´ ê³ ì • ì‘ì‹œ ì‹œê°„(fixation_duration > 10 í”„ë ˆì„)",
        "9. ë†’ì€ ì •ë©´ ì‘ì‹œ í™•ë¥ (gaze_direction_prob > 0.8)"
    ]
    
    for rule in rules:
        print(f"  {rule}")
    
    print(f"\nğŸ’¡ ì‹¤ì‹œê°„ ê°œì„  ì œì•ˆ:")
    print("-" * 30)
    print("  â€¢ í™”ë©´ ì¤‘ì•™(Â±100í”½ì…€) ì‘ì‹œ ì‹œ ì§‘ì¤‘ ë³´ë„ˆìŠ¤")
    print("  â€¢ 3ì´ˆ ì´ìƒ ê³ ì • ì‘ì‹œ ì‹œ ì§‘ì¤‘ í™•ë¥  ì¦ê°€")  
    print("  â€¢ ë¨¸ë¦¬ê°€ 15ë„ ì´ë‚´ ê°ë„ì¼ ë•Œ ì§‘ì¤‘ ê°€ì‚°ì ")
    print("  â€¢ ê¸‰ì†í•œ ì‹œì„  ì´ë™ ì‹œ ì£¼ì˜ì‚°ë§Œ íŒì •")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” XGBoost ì§‘ì¤‘ë„ ëª¨ë¸ ë¶„ì„ ë„êµ¬")
    print("=" * 60)
    print("ì´ ë„êµ¬ëŠ” ëª¨ë¸ì´ ì–´ë–»ê²Œ ì§‘ì¤‘ë„ë¥¼ íŒë‹¨í•˜ëŠ”ì§€ ë¶„ì„í•©ë‹ˆë‹¤.\n")
    
    while True:
        print("ğŸ“‹ ë¶„ì„ ë©”ë‰´:")
        print("1. í•™ìŠµ ë°ì´í„° íŒ¨í„´ ë¶„ì„")
        print("2. ëª¨ë¸ íŠ¹ì§• ì¤‘ìš”ë„ ë¶„ì„") 
        print("3. ëª¨ë¸ ê²°ì • ê²½ê³„ ë¶„ì„")
        print("4. ì§‘ì¤‘ë„ íŒë‹¨ ê·œì¹™ ìƒì„±")
        print("5. ì „ì²´ ë¶„ì„ ì‹¤í–‰")
        print("0. ì¢…ë£Œ")
        
        choice = input("\nì„ íƒí•˜ì„¸ìš” (0-5): ").strip()
        
        if choice == '1':
            thresholds = analyze_dataset_patterns()
        elif choice == '2':
            importance = analyze_model_importance()
        elif choice == '3':
            analyze_decision_boundaries()
        elif choice == '4':
            generate_concentration_rules()
        elif choice == '5':
            print("\nğŸš€ ì „ì²´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            thresholds = analyze_dataset_patterns()
            importance = analyze_model_importance()
            analyze_decision_boundaries()
            generate_concentration_rules()
            print("\nâœ… ì „ì²´ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        elif choice == '0':
            print("ğŸ‘‹ ë¶„ì„ ë„êµ¬ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 0-5 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        
        input("\nEnterë¥¼ ëˆŒëŸ¬ ê³„ì†...")
        print("\n" + "="*60 + "\n")

if __name__ == "__main__":
    main()
