import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from ml_classifier import ConcentrationClassifier

def train_xgboost_concentration_model():
    """XGBoost ê¸°ë°˜ ì§‘ì¤‘ë„ ëª¨ë¸ í•™ìŠµ (ë¶ˆê· í˜• ë°ì´í„° ë³´ì™„)"""
    
    print("=== XGBoost ê¸°ë°˜ 3í´ë˜ìŠ¤ ì§‘ì¤‘ë„ ëª¨ë¸ í•™ìŠµ ===")
    print("ğŸš€ ë¶ˆê· í˜• ë°ì´í„° ë³´ì™„ ê¸°ëŠ¥ í¬í•¨\n")
    
    # 1. ë°ì´í„° ë¡œë“œ
    print("1ë‹¨ê³„: ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ ë¡œë“œ...")
    csv_path = "./processed_data/json_features_3class_dataset.csv"
    
    try:
        df = pd.read_csv(csv_path)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìƒ˜í”Œ")
    except FileNotFoundError:
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        print("ğŸ’¡ ë¨¼ì € data_processor.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.")
        return
    
    # 2. ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ë° íŠ¹ì§• ì¤€ë¹„
    print("\n2ë‹¨ê³„: íŠ¹ì§• ì¤€ë¹„...")
    classifier = ConcentrationClassifier()
    X, y, feature_columns = classifier.prepare_features(df)
    
    print(f"íŠ¹ì§• ë²¡í„° ì°¨ì›: {X.shape[1]}")
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(X)}")
    
    # 3. ê°œì¸ë³„ ë°ì´í„° ë¶„í• 
    print("\n3ë‹¨ê³„: ê°œì¸ë³„ ë°ì´í„° ë¶„í• ...")
    unique_persons = df['metaid'].unique()
    np.random.seed(42)
    train_persons = np.random.choice(unique_persons, 
                                   size=int(len(unique_persons) * 0.8), 
                                   replace=False)
    
    train_mask = df['metaid'].isin(train_persons)
    
    X_train = X[train_mask]
    y_train = y[train_mask]
    X_test = X[~train_mask]
    y_test = y[~train_mask]
    
    print(f"í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ ({len(train_persons)}ëª…)")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ ({len(unique_persons) - len(train_persons)}ëª…)")
    
    # 4. ê³ ê¸‰ ë°ì´í„° ì „ì²˜ë¦¬ (ë¶ˆê· í˜• ë³´ì™„)
    print("\n4ë‹¨ê³„: ë¶ˆê· í˜• ë°ì´í„° ë³´ì™„...")
    
    # ë¦¬ìƒ˜í”Œë§ ë°©ë²• ì„ íƒ
    print("ì‚¬ìš©í•  ë¦¬ìƒ˜í”Œë§ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. auto (ìë™ ì„ íƒ)")
    print("2. smote (ê¸°ë³¸ SMOTE)")
    print("3. borderline (Borderline SMOTE)")
    print("4. adasyn (ADASYN)")
    print("5. smote_tomek (SMOTE + Tomek)")
    
    choice = input("ì„ íƒ (1-5, Enter=ìë™): ").strip()
    method_map = {
        '1': 'auto', '2': 'smote', '3': 'borderline', 
        '4': 'adasyn', '5': 'smote_tomek', '': 'auto'
    }
    method = method_map.get(choice, 'auto')
    
    X_train_processed, y_train_processed = classifier.prepare_data_advanced(X_train, y_train, method)
    
    # 5. XGBoost ëª¨ë¸ í•™ìŠµ
    print("\n5ë‹¨ê³„: XGBoost ëª¨ë¸ í•™ìŠµ...")
    
    tune_params = input("í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ìˆ˜í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").lower().strip()
    tune_hyperparams = tune_params in ['y', 'yes']
    
    if tune_hyperparams:
        print("âš ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (10-30ë¶„)")
    
    # XGBoost í•™ìŠµ
    print("ğŸŒŸ XGBoost í•™ìŠµ ì¤‘...")
    training_results = classifier.train_xgboost_simple(X_train_processed, y_train_processed)

        
    print(f"âœ… XGBoost CV ì ìˆ˜ (F1-Macro): {training_results['cv_mean']:.4f} (+/- {training_results['cv_std']*2:.4f})")
    
    # 6. ëª¨ë¸ í‰ê°€
    print("\n6ë‹¨ê³„: ëª¨ë¸ ì„±ëŠ¥ í‰ê°€...")
    evaluation = classifier.evaluate_advanced(X_test, y_test, feature_columns)
    
    # 7. ê²°ê³¼ ì¶œë ¥
    print(f"\n=== ğŸ¯ ìµœì¢… í‰ê°€ ê²°ê³¼ ===")
    print(f"ëª¨ë¸: {training_results['model_type']}")
    print(f"ì •í™•ë„: {evaluation['accuracy']:.4f}")
    print(f"F1 Score (Macro): {evaluation['f1_macro']:.4f}")
    print(f"F1 Score (Weighted): {evaluation['f1_weighted']:.4f}")
    
    # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
    print(f"\ní´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
    report = evaluation['classification_report']
    for class_name in ['ë¹„ì§‘ì¤‘', 'ì£¼ì˜ì‚°ë§Œ', 'ì§‘ì¤‘']:
        if class_name in report:
            precision = report[class_name]['precision']
            recall = report[class_name]['recall']
            f1 = report[class_name]['f1-score']
            print(f"  {class_name:>6}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}")
    
    # í˜¼ë™ í–‰ë ¬
    print(f"\ní˜¼ë™ í–‰ë ¬:")
    cm = evaluation['confusion_matrix']
    print("         ì˜ˆì¸¡")
    print("ì‹¤ì œ    ë¹„ì§‘ì¤‘  ì£¼ì˜ì‚°ë§Œ  ì§‘ì¤‘")
    class_names_list = ['ë¹„ì§‘ì¤‘', 'ì£¼ì˜ì‚°ë§Œ', 'ì§‘ì¤‘']
    for i, true_class in enumerate(class_names_list):
        row = f"{true_class:>6}  "
        for j in range(3):
            row += f"{cm[i][j]:>6}  "
        print(row)
    
    # 8. ëª¨ë¸ ì €ì¥
    print(f"\n7ë‹¨ê³„: ëª¨ë¸ ì €ì¥...")
    model_path = "./xgboost_3class_concentration_classifier.pkl"
    classifier.save_model(model_path, feature_columns)
    
    print(f"\nğŸ‰ XGBoost ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_path}")
    print("ğŸš€ inference.pyë¡œ ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    train_xgboost_concentration_model()
