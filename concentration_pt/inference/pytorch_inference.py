import torch
import cv2
import numpy as np
from collections import deque
import time
import argparse
import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from models.pytorch_concentration import create_model
from utils.face_detector import FaceDetector
from utils.attention_features import AttentionFeatureExtractor

class PyTorchConcentrationInference:
    """PyTorch ëª¨ë¸ ê¸°ë°˜ ì‹¤ì‹œê°„ ì§‘ì¤‘ë„ ë¶„ì„"""
    
    def __init__(self, model_path, model_type='lstm', device='auto'):
        # ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ìë™ ê°ì§€)
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        self.model_type = model_type
        
        # ëª¨ë¸ ë¡œë“œ
        self.load_model(model_path)
        
        # ì–¼êµ´ ê²€ì¶œ ë° íŠ¹ì§• ì¶”ì¶œê¸°
        self.face_detector = FaceDetector()
        self.feature_extractor = AttentionFeatureExtractor()
        
        # 30í”„ë ˆì„ ë²„í¼
        self.frame_buffer = deque(maxlen=30)
        self.analysis_results = []
        
        # UI ì„¤ì •
        self.cls_name = {0: 'Not Focused', 1: 'Focused'}
        self.cls_color = {0: (0, 0, 255), 1: (0, 255, 0)}
        
        # ì§ì‚¬ê°í˜• ì§‘ì¤‘ ì˜ì—­
        self.attention_zone_width = 720
        self.attention_zone_height = 180
        
        print(f"âœ… PyTorch ì§‘ì¤‘ë„ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ëª¨ë¸: {model_type}")
        print(f"ë””ë°”ì´ìŠ¤: {self.device}")
        
        # GPU ë©”ëª¨ë¦¬ ì •ë³´ ì¶œë ¥
        if self.device.type == 'cuda':
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"ğŸš€ GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
            
    def load_model(self, model_path):
        """PyTorch ëª¨ë¸ ë¡œë“œ"""
        print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ: {model_path}")
        
        # CPUì—ì„œ ë¡œë“œ í›„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        checkpoint = torch.load(model_path, map_location='cpu')
        
        # ëª¨ë¸ ìƒì„±
        self.model = create_model(self.model_type, input_dim=31)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # ëª¨ë¸ ì •ë³´
        total_params = sum(p.numel() for p in self.model.parameters())
        print(f"ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ")
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (F1: {checkpoint.get('val_f1', 'N/A'):.4f})")
        
        # GPU ì‚¬ìš© ì‹œ ì›Œë°ì—…
        if self.device.type == 'cuda':
            self.warmup_gpu()
    
    def warmup_gpu(self):
        """GPU ì›Œë°ì—… (ì²« ì¶”ë¡  ì†ë„ ìµœì í™”)"""
        print("ğŸ”¥ GPU ì›Œë°ì—… ì¤‘...")
        dummy_input = torch.randn(1, 30, 31).to(self.device)
        
        with torch.no_grad():
            for _ in range(3):
                _ = self.model(dummy_input)
        
        if self.device.type == 'cuda':
            torch.cuda.synchronize()
        print("âœ… GPU ì›Œë°ì—… ì™„ë£Œ")
    
    def extract_frame_features(self, frame):
        """í”„ë ˆì„ì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
        # ì–¼êµ´ ê²€ì¶œ
        face_box = self.face_detector.detect_face(frame)
        
        # íŠ¹ì§• ì¶”ì¶œ (26ì°¨ì› + 5ì°¨ì› attention = 31ì°¨ì›)
        features, attention_features = self.feature_extractor.extract_features(frame, face_box)
        
        # íŠ¹ì§• ê²°í•©
        combined_features = np.concatenate([
            features,
            [
                attention_features['central_focus'],
                attention_features['gaze_fixation'],
                attention_features['head_stability'],
                attention_features['face_orientation'],
                attention_features['attention_score']
            ]
        ])
        
        return combined_features, face_box, attention_features
    
    def predict_concentration(self):
        """30í”„ë ˆì„ìœ¼ë¡œ ì§‘ì¤‘ë„ ì˜ˆì¸¡"""
        if len(self.frame_buffer) < 30:
            return None, 0.0
        
        # 30í”„ë ˆì„ì„ í…ì„œë¡œ ë³€í™˜
        sequence = torch.FloatTensor(list(self.frame_buffer)).unsqueeze(0)  # [1, 30, 31]
        sequence = sequence.to(self.device)
        
        # ì„±ëŠ¥ ì¸¡ì •
        if self.device.type == 'cuda':
            torch.cuda.synchronize()
        start_time = time.time()
        
        # ëª¨ë¸ ì˜ˆì¸¡
        with torch.no_grad():
            output = self.model(sequence)
            confidence = output.item()
            prediction = 1 if confidence > 0.5 else 0
        
        # ì¶”ë¡  ì‹œê°„ ê³„ì‚°
        if self.device.type == 'cuda':
            torch.cuda.synchronize()
        inference_time = time.time() - start_time
        
        return prediction, confidence, inference_time
    
    def run_realtime_analysis(self):
        """ì‹¤ì‹œê°„ ë¶„ì„ ì‹¤í–‰"""
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        if not cap.isOpened():
            print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        frame_count = 0
        analysis_count = 0
        start_time = time.time()
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        inference_times = deque(maxlen=10)
        
        print("ğŸš€ PyTorch ì‹¤ì‹œê°„ ì§‘ì¤‘ë„ ë¶„ì„ ì‹œì‘")
        print("30í”„ë ˆì„ì´ ìŒ“ì´ë©´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("ESC í‚¤ë¡œ ì¢…ë£Œ")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # í”„ë ˆì„ë³„ íŠ¹ì§• ì¶”ì¶œ
            features, face_box, attention_features = self.extract_frame_features(frame)
            self.frame_buffer.append(features)
            
            # 30í”„ë ˆì„ë§ˆë‹¤ ë¶„ì„
            if frame_count % 30 == 0 and len(self.frame_buffer) == 30:
                analysis_count += 1
                prediction, confidence, inference_time = self.predict_concentration()
                
                if prediction is not None:
                    inference_times.append(inference_time)
                    
                    # ê²°ê³¼ ì €ì¥
                    result = {
                        'frame': frame_count,
                        'analysis': analysis_count,
                        'prediction': prediction,
                        'confidence': confidence,
                        'inference_time': inference_time,
                        'timestamp': time.time()
                    }
                    self.analysis_results.append(result)
                    
                    # ê²°ê³¼ ì¶œë ¥ (ì„±ëŠ¥ ì •ë³´ í¬í•¨)
                    status = "ğŸ¯ ì§‘ì¤‘" if prediction == 1 else "âŒ ë¹„ì§‘ì¤‘"
                    avg_inference_time = np.mean(list(inference_times)) if inference_times else 0
                    
                    print(f"[ë¶„ì„ {analysis_count:3d}] {status} | "
                          f"í™•ì‹ ë„: {confidence:.3f} | "
                          f"ì¶”ë¡ ì‹œê°„: {inference_time*1000:.1f}ms | "
                          f"í‰ê· : {avg_inference_time*1000:.1f}ms")
            
            # UI ê·¸ë¦¬ê¸°
            self.draw_ui(frame, face_box, attention_features, inference_times)
            
            # FPS ë° ì„±ëŠ¥ í‘œì‹œ
            elapsed = time.time() - start_time
            fps = frame_count / elapsed if elapsed > 0 else 0
            cv2.putText(frame, f"FPS: {fps:.1f}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í‘œì‹œ (CUDAì¸ ê²½ìš°)
            if self.device.type == 'cuda':
                memory_used = torch.cuda.memory_allocated() / 1024**2  # MB
                cv2.putText(frame, f"GPU Mem: {memory_used:.0f}MB", (10, 70), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            
            # ë²„í¼ ìƒíƒœ
            buffer_status = f"Buffer: {len(self.frame_buffer)}/30"
            cv2.putText(frame, buffer_status, (10, 110), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            
            cv2.imshow("PyTorch Concentration Analysis", frame)
            
            if cv2.waitKey(1) & 0xFF == 27:  # ESC
                break
        
        # ê²°ê³¼ ìš”ì•½
        self.print_summary(start_time, inference_times)
        cap.release()
        cv2.destroyAllWindows()
    
    def draw_ui(self, frame, face_box, attention_features, inference_times):
        """UI ê·¸ë¦¬ê¸° (ì„±ëŠ¥ ì •ë³´ í¬í•¨)"""
        # ìµœê·¼ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        if self.analysis_results:
            recent_result = self.analysis_results[-1]
            prediction = recent_result['prediction']
            confidence = recent_result['confidence']
            
            color = self.cls_color[prediction]
            status_text = "FOCUSED" if prediction == 1 else "NOT FOCUSED"
            
            cv2.putText(frame, f"Status: {status_text}", (10, 160), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
            cv2.putText(frame, f"Confidence: {confidence:.3f}", (10, 200), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        
        # ì–¼êµ´ ë°•ìŠ¤
        if face_box is not None:
            x, y, w, h = face_box
            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
        
        # ì§‘ì¤‘ ì˜ì—­ (ì§ì‚¬ê°í˜•)
        center_x, center_y = frame.shape[1] // 2, frame.shape[0] // 2
        rect_left = center_x - self.attention_zone_width // 2
        rect_right = center_x + self.attention_zone_width // 2
        rect_top = center_y - self.attention_zone_height // 2
        rect_bottom = center_y + self.attention_zone_height // 2
        
        cv2.rectangle(frame, (rect_left, rect_top), (rect_right, rect_bottom), (255, 255, 255), 2)
        
        # ì„±ëŠ¥ ì •ë³´
        avg_inference_time = np.mean(list(inference_times)) if inference_times else 0
        cv2.putText(frame, f"Avg Inference: {avg_inference_time*1000:.1f}ms", (10, frame.shape[0] - 80), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # ëª¨ë¸ ì •ë³´
        cv2.putText(frame, f"Model: PyTorch {self.model_type.upper()}", (10, frame.shape[0] - 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(frame, f"Device: {self.device}", (10, frame.shape[0] - 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (128, 128, 128), 1)
    
    def print_summary(self, start_time, inference_times):
        """ê²°ê³¼ ìš”ì•½ (ì„±ëŠ¥ í¬í•¨)"""
        total_time = time.time() - start_time
        
        print(f"\n{'='*70}")
        print(f"ğŸ“Š PyTorch ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼")
        print(f"{'='*70}")
        print(f"ëª¨ë¸: {self.model_type}")
        print(f"ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.1f}ì´ˆ")
        print(f"ì´ ë¶„ì„ íšŸìˆ˜: {len(self.analysis_results)}ë²ˆ")
        
        if inference_times:
            avg_inference_time = np.mean(list(inference_times))
            min_inference_time = np.min(list(inference_times))
            max_inference_time = np.max(list(inference_times))
            
            print(f"í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_inference_time*1000:.2f}ms")
            print(f"ìµœì†Œ ì¶”ë¡  ì‹œê°„: {min_inference_time*1000:.2f}ms")
            print(f"ìµœëŒ€ ì¶”ë¡  ì‹œê°„: {max_inference_time*1000:.2f}ms")
        
        if self.analysis_results:
            focus_count = sum(1 for r in self.analysis_results if r['prediction'] == 1)
            focus_ratio = focus_count / len(self.analysis_results) * 100
            
            print(f"ì§‘ì¤‘ íŒì •: {focus_count}/{len(self.analysis_results)}ë²ˆ ({focus_ratio:.1f}%)")
            
            avg_confidence = np.mean([r['confidence'] for r in self.analysis_results])
            print(f"í‰ê·  í™•ì‹ ë„: {avg_confidence:.3f}")
        
        print(f"{'='*70}")

def main():
    parser = argparse.ArgumentParser(description='PyTorch ì§‘ì¤‘ë„ ëª¨ë¸ ì‹¤ì‹œê°„ ì¶”ë¡ ')
    parser.add_argument('--model', type=str, required=True,
                       help='PyTorch ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.pt)')
    parser.add_argument('--model_type', type=str, default='lstm',
                       choices=['lstm', 'transformer', 'cnn1d'],
                       help='ëª¨ë¸ íƒ€ì…')
    parser.add_argument('--device', type=str, default='auto',
                       choices=['auto', 'cpu', 'cuda'],
                       help='ë””ë°”ì´ìŠ¤ ì„ íƒ (auto: ìë™ê°ì§€)')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.model):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.model}")
        return
    
    # ì¶”ë¡ ê¸° ìƒì„± ë° ì‹¤í–‰
    inference = PyTorchConcentrationInference(
        model_path=args.model, 
        model_type=args.model_type,
        device=args.device
    )
    
    try:
        inference.run_realtime_analysis()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
