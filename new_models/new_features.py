import os
import cv2
import torch
import pickle
import numpy as np
import platform
import re
from tqdm import tqdm
from torchvision import transforms
from models.cnn_encoder import CNNEncoder
import multiprocessing

# â”€â”€â”€ ê²½ë¡œ ë³€í™˜ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def windows_path_to_wsl(path: str) -> str:
    """
    WSL í™˜ê²½ì¼ ë•Œ 'C:\\...' ê²½ë¡œë¥¼ '/mnt/c/...' í˜•íƒœë¡œ ë³€í™˜.
    Windows ë„¤ì´í‹°ë¸Œ Pythonì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜.
    """
    if platform.system() == "Linux" and re.match(r"^[A-Za-z]:\\", path):
        drive, rest = path.split(":", 1)
        rest = rest.replace("\\", "/")            # ë°±ìŠ¬ë˜ì‹œë¥¼ ìŠ¬ë˜ì‹œë¡œ ì¹˜í™˜
        return "/mnt/" + drive.lower() + rest     # f-string ëŒ€ì‹  ë¬¸ìì—´ ë§ì…ˆ ì‚¬ìš©
    return path

# â”€â”€â”€ ì•ˆì •ì ì¸ ì´ë¯¸ì§€ ì½ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def robust_imread(path: str):
    """
    1) cv2.imread ì‹œë„
    2) Windows UNC prefix(\\\\?\\) ì¬ì‹œë„
    3) open + cv2.imdecode ìš°íšŒ
    """
    img = cv2.imread(path)
    if img is not None:
        return img

    if os.name == "nt":
        unc = r"\\\\?\\" + os.path.abspath(path)
        img = cv2.imread(unc)
        if img is not None:
            return img

    try:
        data = open(path, "rb").read()
        arr = np.frombuffer(data, np.uint8)
        return cv2.imdecode(arr, cv2.IMREAD_COLOR)
    except Exception:
        return None

# â”€â”€â”€ ì´ë¯¸ì§€ ì „ì²˜ë¦¬(transform) ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# â”€â”€â”€ í´ë”ì—ì„œ Tê°œ í”„ë ˆì„ì„ ë¶ˆëŸ¬ì™€ í”¼ì²˜ ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@torch.no_grad()
def extract_features_from_folder(args):
    folder, label, device_str, T = args

    # í´ë” ì²´í¬
    if not os.path.exists(folder):
        return None

    # ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    imgs = sorted([
        f for f in os.listdir(folder)
        if f.lower().endswith((".jpg", ".jpeg", ".png"))
    ])
    if len(imgs) < T:
        return None

    # ëª¨ë¸ ë¡œë“œ
    device = torch.device(device_str)
    model = CNNEncoder().to(device)
    model.eval()

    # Tê°œ í”„ë ˆì„ ì½ì–´ ì „ì²˜ë¦¬
    frames = []
    for fn in imgs[:T]:
        path = os.path.join(folder, fn)
        path_conv = windows_path_to_wsl(path)
        img_bgr = robust_imread(path_conv)
        if img_bgr is None:
            return None
        frames.append(transform(img_bgr))

    # (1, T, C, H, W) í˜•íƒœë¡œ ëª¨ë¸ì— ì…ë ¥
    inp = torch.stack(frames).unsqueeze(0).to(device)
    feat = model(inp).squeeze(0).cpu()  # (feature_dim,) ë˜ëŠ” (T, feature_dim)
    return feat, torch.tensor(label, dtype=torch.float32)

# â”€â”€â”€ ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ í”¼ì²˜ ì¶”ì¶œ í›„ .pkl ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def save_features_as_pkl(dataset_link, save_path,
                         device_str="cuda", T=30, num_workers=4):
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    args_list = [(p, l, device_str, T) for p, l in dataset_link]
    features, labels = [], []

    with multiprocessing.Pool(processes=num_workers) as pool:
        for res in tqdm(pool.imap_unordered(extract_features_from_folder, args_list),
                        total=len(args_list),
                        desc=f"ğŸ“¦ Extract â†’ {os.path.basename(save_path)}"):
            if res is None:
                continue
            fvec, lbl = res
            features.append(fvec)
            labels.append(lbl)

    with open(save_path, "wb") as f:
        pickle.dump({"features": features, "labels": labels}, f)
    print(f"[âœ… ì €ì¥ ì™„ë£Œ] {save_path} | ìƒ˜í”Œ ìˆ˜: {len(features)}")

# â”€â”€â”€ ë©”ì¸ ì‹¤í–‰ë¶€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    multiprocessing.freeze_support()

    # 1) ì²˜ë¦¬í•  ì„¸ ê°œì˜ ì…ë ¥ í´ë”
    input_dirs = [
        r"C:/Users/user/Downloads/126.eye/0801/t/o/og/TS/TS/all_image_30/134_face_crop",
        r"C:/Users/user/Downloads/126.eye/0801/t/o/og/TS/TS/all_image_30/135_face_crop", #íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê²½ë¡œë¥¼ ì˜ì–´ë¡œ ë°”ê¾¸ì–´ì•¼í•¨.
        r"C:/Users/user/Downloads/126.eye/0801/t/o/og/TS/TS/all_image_30/136_face_crop"
    ]

    # 2) ê° í´ë”ì—ì„œ (í´ë”ê²½ë¡œ, ë¼ë²¨) ë¦¬ìŠ¤íŠ¸ ìƒì„±
    all_dataset_link = []
    for ts_dir in input_dirs:
        class_names = sorted(os.listdir(ts_dir))
        label_to_idx = {name: idx for idx, name in enumerate(class_names)}
        for name in class_names:
            folder = os.path.join(ts_dir, name)
            if os.path.isdir(folder):
                all_dataset_link.append((folder, label_to_idx[name]))
    print(f"ì „ì²´ ìƒ˜í”Œ í´ë” ìˆ˜: {len(all_dataset_link)}")

    # 3) í”¼ì²˜ ì €ì¥ ì„¤ì •
    save_path = r"C:/Users/user/Desktop/brainbuddy_AI/cnn_features/features/0801_TS_features.pkl"
    device_str = "cuda:0" if torch.cuda.is_available() else "cpu"
    num_workers = min(multiprocessing.cpu_count(), 4)
    T = 30  # í”„ë ˆì„ ìˆ˜

    # 4) í”¼ì²˜ ì¶”ì¶œ ë° ë‹¨ì¼ .pkl ì €ì¥
    save_features_as_pkl(all_dataset_link, save_path,
                         device_str=device_str, T=T, num_workers=num_workers)
