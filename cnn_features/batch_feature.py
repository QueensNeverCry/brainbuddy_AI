import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'# TF Í≤ΩÍ≥† log Î¨¥Ïãú
import cv2
import torch
import pickle
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from tqdm import tqdm
from models.cnn_encoder import CNNEncoder
from models.face_crop_yolo import crop_face_batch_chunked


# Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# Dataset Ï†ïÏùò
class VideoFolderDataset(Dataset):
    def __init__(self, dataset_link, T=100):
        self.dataset_link = dataset_link
        self.T = T

    def __len__(self):
        return len(self.dataset_link)

    def __getitem__(self, idx):
        frame_folder, label = self.dataset_link[idx]
        img_files = sorted([
            f for f in os.listdir(frame_folder)
            if f.lower().endswith(('.jpg', '.jpeg', '.png'))
        ])
        if len(img_files) < self.T:
            raise ValueError(f"Not enough frames in {frame_folder}: {len(img_files)} < {self.T}")

        img_paths = [os.path.join(frame_folder, f) for f in img_files[:self.T]]
        frames = []

        imgs = [cv2.imread(p) for p in img_paths]
        crops = crop_face_batch_chunked(imgs, batch_size=2)

        for crop in crops:
            tensor = transform(crop)
            frames.append(tensor)

        frames_tensor = torch.stack(frames)  # [T, 3, 224, 224]
        return frames_tensor, torch.tensor(label, dtype=torch.float32)

# Î∞∞Ïπò Îã®ÏúÑÎ°ú feature Ï∂îÏ∂ú
@torch.no_grad()
def extract_batch_features(dataloader, model, device):
    all_features = []
    all_labels = []

    for batch_frames, batch_labels in tqdm(dataloader, desc="üöÄ Î∞∞Ïπò Ï≤òÎ¶¨ Ï§ë"):
        # batch_frames: [B, T, 3, 224, 224]
        batch_frames = batch_frames.to(device)  # Ï†ÑÏ≤¥ Î∞∞Ïπò GPUÎ°ú Ïù¥Îèô
        batch_features = model(batch_frames)    # [B, T, 1280]
        all_features.extend(batch_features.cpu())  # Í∞ÅÍ∞Å [T, 1280]Ïù∏ ÌÖêÏÑúÎì§
        all_labels.extend(batch_labels)

    return all_features, all_labels

def save_features_as_pkl(dataset_link, save_path, T=100, batch_size=4, num_workers=2):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CNNEncoder().to(device)
    model.eval()

    dataset = VideoFolderDataset(dataset_link, T)
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
        collate_fn=collate_skip_invalid  # ÏòàÏô∏Í∞Ä Î∞úÏÉùÌïú ÏÉòÌîåÏùÄ Î¨¥Ïãú
    )

    features, labels = extract_batch_features(dataloader, model, device)

    with open(save_path, "wb") as f:
        pickle.dump({
            "features": features,  # [N x Tensor [T, 1280]]
            "labels": labels       # [N x Tensor]
        }, f)

    print(f"[‚úÖ Ï†ÄÏû• ÏôÑÎ£å] {save_path} | Ï¥ù ÏÉòÌîå: {len(features)}")

# collate_fn: ÏòàÏô∏ Î∞úÏÉù ÏÉòÌîå Î¨¥Ïãú
def collate_skip_invalid(batch):
    valid = [item for item in batch if item is not None]
    if not valid:
        return torch.empty(0), torch.empty(0)
    frames, labels = zip(*valid)
    return torch.stack(frames), torch.stack(labels)

# Î©îÏù∏ Ïã§Ìñâ
if __name__ == "__main__":
    
    with open("preprocess2/pickle_labels/train/20_01.pkl", "rb") as f:
        dataset_link = pickle.load(f)

    save_features_as_pkl(
        dataset_link,
        save_path="cnn_features/features/train_20_01_batch.pkl",
        T=100,
        batch_size=4,  # GPU Î©îÎ™®Î¶¨Ïóê Îî∞Îùº Ï°∞Ï†à
        num_workers=2
    )
