import os
import cv2
import torch
import pickle
from tqdm import tqdm
import mediapipe as mp
from torchvision import transforms
from models.cnn_encoder import CNNEncoder
from models.face_crop import crop_face
import multiprocessing

os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
mp_face_detection = mp.solutions.face_detection

transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

@torch.no_grad()
<<<<<<< HEAD
def extract_features_from_folder(frame_folder, model, device, face_detector, T=100):
    global skip_path_count, skip_frame_count, load_fail_count, success_count
    # í•´ë‹¹ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ íŒ¨ìŠ¤
=======
def extract_features_from_folder(args):
    frame_folder, label, device_str, T = args

    device = torch.device(device_str)
    model = CNNEncoder().to(device)
    model.eval()

    skip_path_count = 0
    skip_frame_count = 0
    load_fail_count = 0
    success_count = 0

>>>>>>> origin/main
    if not os.path.exists(frame_folder):
        skip_path_count += 1
        return None

    img_files = sorted([
        f for f in os.listdir(frame_folder)
        if f.lower().endswith(('.jpg', '.jpeg', '.png'))
    ])

    if len(img_files) < T:
        skip_frame_count += 1
        return None

    img_paths = [os.path.join(frame_folder, f) for f in img_files[:T]]
    frames = []

<<<<<<< HEAD
   
    for path in img_paths:
        img = cv2.imread(path)
        face_crop = crop_face(img, face_detector) #ì–¼êµ´ì´ ì—†ëŠ” ê²½ìš° í”„ë ˆì„ ì „ì²´ ë°˜í™˜
        tensor = transform(face_crop)
        frames.append(tensor)
=======
    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detector:
        for path in img_paths:
            img = cv2.imread(path)
            if img is None:
                load_fail_count += 1
                return None
            face_crop = crop_face(img, face_detector)
            tensor = transform(face_crop)
            frames.append(tensor)
>>>>>>> origin/main

    frames_tensor = torch.stack(frames).unsqueeze(0).to(device)
    features = model(frames_tensor).squeeze(0).cpu()

    success_count += 1
    return features, torch.tensor(label, dtype=torch.float32), skip_path_count, skip_frame_count, load_fail_count, success_count


def save_features_as_pkl(dataset_link, save_path, device_str="cuda", T=100, num_workers=4):
    # ê° í”„ë¡œì„¸ìŠ¤ì— ì „ë‹¬í•  ì¸ì íŠœí”Œ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°
    args_list = [(frame_folder, label, device_str, T) for frame_folder, label in dataset_link]

    all_features = []
    all_labels = []
<<<<<<< HEAD
    
    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detector:
        for frame_folder, label in tqdm(dataset_link,desc="ğŸ“¦ Feature ì¶”ì¶œ ì¤‘", total=len(dataset_link)):
            features = extract_features_from_folder(frame_folder, model, device,face_detector, T)
            if features is None:
                continue
            all_features.append(features)  # Tensor [100, 1280]
            all_labels.append(torch.tensor(label, dtype=torch.float32))
=======

    skip_path_total = 0
    skip_frame_total = 0
    load_fail_total = 0
    success_total = 0

    with multiprocessing.Pool(processes=num_workers) as pool:
        for result in tqdm(pool.imap_unordered(extract_features_from_folder, args_list), total=len(args_list), desc="ğŸ“¦ Feature ì¶”ì¶œ ì¤‘"):
            if result is None:
                continue
            features, label, sp, sf, lf, sc = result
            all_features.append(features)
            all_labels.append(label)

            skip_path_total += sp
            skip_frame_total += sf
            load_fail_total += lf
            success_total += sc
>>>>>>> origin/main

    with open(save_path, "wb") as f:
        pickle.dump({
            "features": all_features,
            "labels": all_labels
        }, f)

    print(f"[âœ… ì €ì¥ ì™„ë£Œ] {save_path} | ì´ ìƒ˜í”Œ: {len(all_features)}")
    print("\nğŸ“Š ì²˜ë¦¬ í†µê³„:")
<<<<<<< HEAD
    print(f"  [ê²½ë¡œ ì—†ìŒ] {skip_path_count}")
    print(f"  [í”„ë ˆì„ ë¶€ì¡±] {skip_frame_count}")
    print(f"  [ì •ìƒ ì¶”ì¶œ ì™„ë£Œ] {success_count}")
=======
    print(f"  [ê²½ë¡œ ì—†ìŒ] {skip_path_total}")
    print(f"  [í”„ë ˆì„ ë¶€ì¡±] {skip_frame_total}")
    print(f"  [ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨] {load_fail_total}")
    print(f"  [ì •ìƒ ì¶”ì¶œ ì™„ë£Œ] {success_total}")

>>>>>>> origin/main

if __name__ == "__main__":
    import sys

    # ë©€í‹°í”„ë¡œì„¸ì‹± ê´€ë ¨ ì•ˆì „ì¥ì¹˜ (íŠ¹íˆ Windowsì—ì„œ ì¤‘ìš”)
    multiprocessing.freeze_support()

    with open("preprocess2/pickle_labels/train/20_03.pkl", "rb") as f:
        dataset_link = pickle.load(f)

<<<<<<< HEAD
=======
    # CPU ì½”ì–´ ìˆ˜ ì œí•œ (GPUê°€ í•˜ë‚˜ë¼ë©´ ë„ˆë¬´ ë§ì´ ëŒë¦¬ì§€ ë§ì)
    max_workers = min(multiprocessing.cpu_count(), 4)

    # GPU í•˜ë‚˜ë§Œ ì‚¬ìš©í•œë‹¤ê³  ê°€ì • (cuda:0)
    device_str = "cuda:0" if torch.cuda.is_available() else "cpu"

>>>>>>> origin/main
    save_features_as_pkl(
        dataset_link,
        save_path="cnn_features/features/train_20_03.pkl",
        device_str=device_str,
        T=100,
        num_workers=max_workers
    )
