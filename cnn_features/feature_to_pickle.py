import os
import cv2
import torch
import pickle
from tqdm import tqdm
from torchvision import transforms
from models.cnn_encoder import CNNEncoder
from models.face_crop import crop_face
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"# ê²½ê³  ìˆ¨ê¹€
"""
íŠ¹ì§•ë²¡í„° ì¶”ì¶œí•˜ê³  pklë¡œ ë³€í™˜
"""

#1. pip uninstall mediapipe #do this to uninstall your current version
#2. pip install mediapipe==0.10.9
#3. python -m cnn_features.feature_to_pickle ì‹¤í–‰

# torchvisionìš© ì´ë¯¸ì§€ ë³€í™˜
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

skip_path_count = 0
skip_frame_count = 0
load_fail_count = 0
success_count = 0

@torch.no_grad()
def extract_features_from_folder(frame_folder, model, device, T=100):
    global skip_path_count, skip_frame_count, load_fail_count, success_count
    # í•´ë‹¹ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ íŒ¨ìŠ¤
    if not os.path.exists(frame_folder):
        print(f"[SKIP] ê²½ë¡œ ì—†ìŒ : {frame_folder}")
        skip_path_count += 1
        return None

    # ì´ë¯¸ì§€ íŒŒì¼ ì •ë ¬
    img_files = sorted([
        f for f in os.listdir(frame_folder)
        if f.lower().endswith(('.jpg', '.jpeg', '.png'))
    ])

    if len(img_files) < T:
        print(f"[SKIP] {frame_folder}: í”„ë ˆì„ ë¶€ì¡± ({len(img_files)}/{T})")
        skip_frame_count += 1
        return None

    # 100ì¥ ê²½ë¡œ ì¶”ì¶œ
    img_paths = [os.path.join(frame_folder, f) for f in img_files[:T]]
    frames = []

    for path in img_paths:
        img = cv2.imread(path)
        if img is None:
            print(f"[ERROR] ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {path}")
            load_fail_count += 1
            return None
        face_crop = crop_face(img) #ì–¼êµ´ì´ ì—†ëŠ” ê²½ìš° í”„ë ˆì„ ì „ì²´ ë°˜í™˜
        tensor = transform(face_crop)
        frames.append(tensor)

    frames_tensor = torch.stack(frames).unsqueeze(0).to(device)  # [1, 100, 3, 224, 224]
    features = model(frames_tensor).squeeze(0).cpu()  # [100, 1280]
    success_count += 1
    return features

def save_features_as_pkl(dataset_link, save_path, device=None, T=100):
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    model = CNNEncoder().to(device)
    model.eval()

    all_features = []
    all_labels = []
    

    for frame_folder, label in tqdm(dataset_link,desc="ğŸ“¦ Feature ì¶”ì¶œ ì¤‘", total=len(dataset_link)):
        features = extract_features_from_folder(frame_folder, model, device, T)
        if features is None:
            continue
        all_features.append(features)  # Tensor [100, 1280]
        all_labels.append(torch.tensor(label, dtype=torch.float32))

    with open(save_path, "wb") as f:
        pickle.dump({
            "features": all_features,  # ë¦¬ìŠ¤íŠ¸ [Nê°œ x Tensor [100, 1280]]
            "labels": all_labels       # ë¦¬ìŠ¤íŠ¸ [Nê°œ x Tensor]
        }, f)

    print(f"[âœ… ì €ì¥ ì™„ë£Œ] {save_path} | ì´ ìƒ˜í”Œ: {len(all_features)}")
    print("\nğŸ“Š ì²˜ë¦¬ í†µê³„:")
    print(f"  [ê²½ë¡œ ì—†ìŒ] {skip_path_count}")
    print(f"  [í”„ë ˆì„ ë¶€ì¡±] {skip_frame_count}")
    print(f"  [ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨] {load_fail_count}")
    print(f"  [ì •ìƒ ì¶”ì¶œ ì™„ë£Œ] {success_count}")

if __name__ == "__main__":
    with open("preprocess2/pickle_labels/train/20_01.pkl", "rb") as f: #(link,label) ê°€ì ¸ì˜¤ê¸°
        dataset_link = pickle.load(f)


    save_features_as_pkl(
        dataset_link,
        save_path="cnn_features/features/train_20_01.pkl", #ì €ì¥ ê²½ë¡œ
        T=100
    )


