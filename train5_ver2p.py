# precision_enhanced_v2.py (Precision 0.9+ ë‹¬ì„±ì„ ìœ„í•œ Version 2 ê°œì„ )
import os
import pickle
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
from tqdm import tqdm
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, recall_score, f1_score, accuracy_score, precision_score
import math
import numpy as np
from torch.cuda.amp import autocast, GradScaler
import time

# ------------------ Precision ìµœì í™” Dataset ------------------
class PrecisionEnhancedDataset(Dataset):
    def __init__(self, data_list, transform=None, is_training=True):
        self.data_list = []
        self.is_training = is_training
        
        if is_training:
            # ë” ê°•í•œ ë°ì´í„° ì¦ê°•ìœ¼ë¡œ robustí•œ íŠ¹ì§• í•™ìŠµ
            self.transform = transform or transforms.Compose([
                transforms.Resize((256, 256)),
                transforms.RandomResizedCrop(224, scale=(0.85, 1.0)),  # ëœ aggressiveí•œ í¬ë¡­
                transforms.RandomHorizontalFlip(p=0.3),  # í™•ë¥  ì¤„ì„
                transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.1),  # ì•½í•œ ìƒ‰ìƒ ë³€í™”
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
        else:
            self.transform = transform or transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
        
        # ë°ì´í„° í’ˆì§ˆ í™•ì¸ì„ ë” ì—„ê²©í•˜ê²Œ
        for folder_path, label in data_list:
            if os.path.isdir(folder_path):
                img_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                if len(img_files) >= 30:  # ì¶©ë¶„í•œ í”„ë ˆì„ ìˆ˜ í™•ë³´
                    self.data_list.append((folder_path, label))

    def __len__(self):
        return len(self.data_list)

    def __getitem__(self, idx):
        folder_path, label = self.data_list[idx]
        img_files = sorted([f for f in os.listdir(folder_path) 
                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])[:30]
        frames = []
        
        for f in img_files:
            img_path = os.path.join(folder_path, f)
            try:
                img_pil = Image.open(img_path).convert('RGB')
                frames.append(self.transform(img_pil))
            except Exception as e:
                continue
        
        # 30ê°œ í”„ë ˆì„ ë³´ì¥
        while len(frames) < 30:
            frames.append(frames[-1] if frames else torch.zeros(3, 224, 224))
        
        video = torch.stack(frames[:30])

        # Fusion features
        fusion_path = os.path.join(folder_path, "fusion_features.pkl")
        if os.path.exists(fusion_path):
            with open(fusion_path, 'rb') as f:
                fusion = torch.tensor(pickle.load(f), dtype=torch.float32)
        else:
            fusion = torch.zeros(5)

        return video, fusion, torch.tensor(label, dtype=torch.float32)

# ------------------ Precision ìµœì í™” CNNEncoder ------------------
class PrecisionEnhancedCNNEncoder(nn.Module):
    """Precision í–¥ìƒì„ ìœ„í•œ ë” robustí•œ CNN ì¸ì½”ë”"""
    def __init__(self, output_dim=1280):
        super().__init__()
        mobilenet = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)
        self.features = mobilenet.features
        self.avgpool = nn.AdaptiveAvgPool2d((4, 4))
        
        # ë” ê¹Šê³  ì •êµí•œ FC ë ˆì´ì–´
        self.fc = nn.Sequential(
            nn.Linear(1280 * 4 * 4, 2048),
            nn.BatchNorm1d(2048),
            nn.GELU(),
            nn.Dropout(0.25),  # ë“œë¡­ì•„ì›ƒ ì¤„ì—¬ì„œ overfitting ë°©ì§€í•˜ë©´ì„œ ì •í™•ë„ ìœ ì§€
            
            nn.Linear(2048, 1280),
            nn.BatchNorm1d(1280),
            nn.GELU(),
            nn.Dropout(0.2),
            
            nn.Linear(1280, output_dim),
            nn.BatchNorm1d(output_dim),
            nn.GELU()
        )

    def forward(self, x):
        B, T, C, H, W = x.shape
        x = x.view(B * T, C, H, W)
        x = self.features(x)
        x = self.avgpool(x)
        x = x.view(B * T, -1)
        x = self.fc(x)
        return x.view(B, T, -1)

# ------------------ Positional Encoding ------------------
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super().__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        seq_len = x.size(0)
        return x + self.pe[:seq_len, :].to(x.device)

# ------------------ Precision ê°•í™” Loss ------------------
class PrecisionFocusedLoss(nn.Module):
    """Precision í–¥ìƒì— íŠ¹í™”ëœ ì†ì‹¤ í•¨ìˆ˜ (ì™„ì „í•œ CUDA ì˜¤ë¥˜ í•´ê²°)"""
    def __init__(self, precision_weight=2.0, pos_weight=1.5):
        super().__init__()
        self.precision_weight = precision_weight
        self.pos_weight_value = pos_weight  # ê°’ë§Œ ì €ì¥
        
    def forward(self, logits, labels):
        # ë§¤ë²ˆ í˜„ì¬ ë””ë°”ì´ìŠ¤ì— ë§ì¶° pos_weight ìƒì„±
        device = logits.device
        pos_weight = torch.tensor([self.pos_weight_value], device=device, dtype=logits.dtype)
        
        # BCE Loss ìƒì„±
        bce_loss = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
        bce = bce_loss(logits, labels)
        
        # Precision ì§‘ì¤‘: False Positive í˜ë„í‹°
        probs = torch.sigmoid(logits)
        false_positives = (1 - labels) * probs
        fp_penalty = torch.mean(false_positives) * self.precision_weight
        
        return bce + fp_penalty

# ------------------ Precision ìµœì í™” ëª¨ë¸ ------------------
class PrecisionEnhancedModelV2(nn.Module):
    """Precision 0.9+ ë‹¬ì„±ì„ ìœ„í•œ ê°œì„ ëœ Version 2"""
    def __init__(self, cnn_feat_dim=1280, fusion_feat_dim=5, d_model=256, nhead=8, num_layers=4):
        super().__init__()
        
        # ë” robustí•œ ì…ë ¥ í”„ë¡œì ì…˜
        self.input_projection = nn.Sequential(
            nn.Linear(cnn_feat_dim, d_model),
            nn.LayerNorm(d_model),
            nn.GELU(),
            nn.Dropout(0.1)
        )
        
        self.pos_encoder = PositionalEncoding(d_model)
        
        # ê°œì„ ëœ Transformer (ë” ê¹Šê³  ì•ˆì •ì )
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 4,
            dropout=0.12,  # ì ë‹¹í•œ ë“œë¡­ì•„ì›ƒ
            activation='gelu',
            batch_first=True,
            norm_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ í’€ë§
        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)
        self.global_max_pool = nn.AdaptiveMaxPool1d(1)
        
        # Attention ë©”ì»¤ë‹ˆì¦˜ (ì¤‘ìš”í•œ í”„ë ˆì„ì— ì§‘ì¤‘)
        self.attention_weights = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.GELU(),
            nn.Linear(d_model // 2, 1),
            nn.Softmax(dim=1)
        )
        
        # Precision ìµœì í™”ë¥¼ ìœ„í•œ ë³´ìˆ˜ì  ë¶„ë¥˜ê¸°
        self.classifier = nn.Sequential(
            # ì²« ë²ˆì§¸ ë¸”ë¡
            nn.Linear(d_model * 3 + fusion_feat_dim, 512),  # attention pooling ì¶”ê°€ë¡œ d_model * 3
            nn.LayerNorm(512),
            nn.GELU(),
            nn.Dropout(0.2),
            
            # ë‘ ë²ˆì§¸ ë¸”ë¡
            nn.Linear(512, 256),
            nn.LayerNorm(256),
            nn.GELU(),
            nn.Dropout(0.15),
            
            # ì„¸ ë²ˆì§¸ ë¸”ë¡ (ë” ë³´ìˆ˜ì )
            nn.Linear(256, 128),
            nn.LayerNorm(128),
            nn.GELU(),
            nn.Dropout(0.1),
            
            # ìµœì¢… ì¶œë ¥
            nn.Linear(128, 1)
        )
        
        # Precisionì„ ìœ„í•œ í™•ì‹ ë„ ì¡°ì ˆ íŒŒë¼ë¯¸í„°
        self.confidence_scaling = nn.Parameter(torch.tensor([1.2]))  # í•™ìŠµ ê°€ëŠ¥í•œ ìŠ¤ì¼€ì¼ë§

    def forward(self, cnn_feats, fusion_feats):
        # CNN íŠ¹ì§• í”„ë¡œì ì…˜
        x = self.input_projection(cnn_feats)  # (B, T, d_model)
        
        # Positional Encoding
        x = x.transpose(0, 1)
        x = self.pos_encoder(x)
        x = x.transpose(0, 1)
        
        # Transformer ì²˜ë¦¬
        transformer_out = self.transformer_encoder(x)  # (B, T, d_model)
        
        # ë‹¤ì¤‘ í’€ë§
        avg_pooled = self.global_avg_pool(transformer_out.transpose(1, 2)).squeeze(-1)  # (B, d_model)
        max_pooled = self.global_max_pool(transformer_out.transpose(1, 2)).squeeze(-1)  # (B, d_model)
        
        # Attention ê¸°ë°˜ í’€ë§ (ì¤‘ìš”í•œ í”„ë ˆì„ì— ì§‘ì¤‘)
        attention_scores = self.attention_weights(transformer_out)  # (B, T, 1)
        attention_pooled = torch.sum(transformer_out * attention_scores, dim=1)  # (B, d_model)
        
        # ëª¨ë“  í’€ë§ ê²°í•©
        pooled_features = torch.cat([avg_pooled, max_pooled, attention_pooled], dim=1)  # (B, d_model * 3)
        
        # Fusion featuresì™€ ê²°í•©
        combined = torch.cat([pooled_features, fusion_feats], dim=1)
        
        # ë¶„ë¥˜
        logits = self.classifier(combined)
        
        # Precision ìµœì í™”: í™•ì‹ ë„ ìŠ¤ì¼€ì¼ë§ (ë” ë³´ìˆ˜ì  ì˜ˆì¸¡)
        scaled_logits = logits * self.confidence_scaling
        
        return scaled_logits

# ------------------ í›ˆë ¨ ë° ê²€ì¦ í•¨ìˆ˜ ------------------
def train_precision_model(model, cnn, loader, criterion, optimizer, device, scaler):
    model.train()
    cnn.train()
    total_loss = 0

    for videos, fusion, labels in tqdm(loader, desc="Precision-Focused Training"):
        videos = videos.to(device, non_blocking=True)
        fusion = fusion.to(device, non_blocking=True)
        labels = labels.to(device, non_blocking=True).unsqueeze(1)

        optimizer.zero_grad()
        
        with autocast():
            cnn_features = cnn(videos)
            logits = model(cnn_features, fusion)
            loss = criterion(logits, labels)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        total_loss += loss.item()

    return total_loss / len(loader)

def validate_precision_model(model, cnn, loader, criterion, device):
    model.eval()
    cnn.eval()
    total_loss = 0

    with torch.no_grad():
        for videos, fusion, labels in tqdm(loader, desc="Precision Validation"):
            videos = videos.to(device, non_blocking=True)
            fusion = fusion.to(device, non_blocking=True)
            labels = labels.to(device, non_blocking=True).unsqueeze(1)
            
            with autocast():
                cnn_features = cnn(videos)
                logits = model(cnn_features, fusion)
                loss = criterion(logits, labels)
            
            total_loss += loss.item()

    return total_loss / len(loader)

def evaluate_precision_metrics(model, cnn, loader, device, threshold=0.8):
    """Precision ì¤‘ì‹¬ í‰ê°€"""
    model.eval()
    cnn.eval()
    
    all_preds = []
    all_labels = []
    all_probs = []
    
    with torch.no_grad():
        for videos, fusion, labels in loader:
            videos = videos.to(device)
            fusion = fusion.to(device)
            
            cnn_features = cnn(videos)
            logits = model(cnn_features, fusion)
            probs = torch.sigmoid(logits).cpu().numpy()
            preds = (probs > threshold).astype(int)
            
            all_probs.extend(probs.flatten())
            all_preds.extend(preds.flatten())
            all_labels.extend(labels.int().numpy().flatten())
    
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, zero_division=0)
    recall = recall_score(all_labels, all_preds, zero_division=0)
    f1 = f1_score(all_labels, all_preds, zero_division=0)
    
    return accuracy, precision, recall, f1, all_probs

def find_optimal_threshold_for_precision(all_probs, all_labels, target_precision=0.9):
    """Precision 0.9+ ë‹¬ì„±ì„ ìœ„í•œ ìµœì  ì„ê³„ê°’ íƒìƒ‰"""
    print("\nğŸ¯ Precision 0.9+ ë‹¬ì„±ì„ ìœ„í•œ ì„ê³„ê°’ ìµœì í™”")
    print("="*60)
    
    best_threshold = 0.5
    best_metrics = {}
    
    for threshold in np.arange(0.5, 0.95, 0.02):  # 0.5ë¶€í„° 0.95ê¹Œì§€ ì„¸ë°€í•˜ê²Œ
        preds = (np.array(all_probs) >= threshold).astype(int)
        
        precision = precision_score(all_labels, preds, zero_division=0)
        recall = recall_score(all_labels, preds, zero_division=0)
        f1 = f1_score(all_labels, preds, zero_division=0)
        accuracy = accuracy_score(all_labels, preds)
        
        print(f"Threshold {threshold:.2f}: Precision={precision:.3f} | Recall={recall:.3f} | F1={f1:.3f} | Acc={accuracy:.3f}")
        
        # Precision 0.9+ ë‹¬ì„±í•˜ëŠ” ì²« ë²ˆì§¸ ì„ê³„ê°’ ì„ íƒ
        if precision >= target_precision and not best_metrics:
            best_threshold = threshold
            best_metrics = {
                'threshold': threshold,
                'precision': precision,
                'recall': recall,
                'f1': f1,
                'accuracy': accuracy
            }
    
    if best_metrics:
        print(f"\nğŸ† Precision {target_precision}+ ë‹¬ì„±!")
        print(f"   - ìµœì  ì„ê³„ê°’: {best_metrics['threshold']:.2f}")
        print(f"   - Precision: {best_metrics['precision']:.3f}")
        print(f"   - Recall: {best_metrics['recall']:.3f}")
        print(f"   - F1-Score: {best_metrics['f1']:.3f}")
        print(f"   - Accuracy: {best_metrics['accuracy']:.3f}")
        return best_metrics['threshold'], best_metrics
    else:
        print(f"âš ï¸ Precision {target_precision} ë¯¸ë‹¬ì„±")
        # ê°€ì¥ ë†’ì€ Precision ë°˜í™˜
        best_precision = 0
        fallback_threshold = 0.8
        for threshold in np.arange(0.5, 0.95, 0.02):
            preds = (np.array(all_probs) >= threshold).astype(int)
            precision = precision_score(all_labels, preds, zero_division=0)
            if precision > best_precision:
                best_precision = precision
                fallback_threshold = threshold
        
        print(f"ğŸ“Š ìµœê³  ë‹¬ì„± Precision: {best_precision:.3f} (ì„ê³„ê°’: {fallback_threshold:.2f})")
        return fallback_threshold, None

def load_data(pkl_files):
    all_data = []
    for pkl_path in pkl_files:
        with open(pkl_path, 'rb') as f:
            data = pickle.load(f)
            all_data.extend(data)
    
    import random
    random.shuffle(all_data)
    return all_data

# ------------------ ë©”ì¸ í›ˆë ¨ í•¨ìˆ˜ ------------------
def main():
    torch.backends.cudnn.benchmark = True
    torch.cuda.empty_cache()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    print("ğŸ¯ **Precision 0.9+ ë‹¬ì„±ì„ ìœ„í•œ Version 2 ê°œì„ **")
    print("="*60)
    print("ğŸš¨ í•µì‹¬ ëª©í‘œ: ì§‘ì¤‘í•˜ëŠ” í•™ìƒì„ 'ì§‘ì¤‘ì•ˆí•¨'ìœ¼ë¡œ ì˜ëª» íŒë‹¨í•˜ëŠ” ê²ƒ ë°©ì§€")
    print("ğŸ“ˆ ì „ëµ: ë³´ìˆ˜ì  ì˜ˆì¸¡, ë†’ì€ í™•ì‹ ë„ì—ì„œë§Œ 'ì§‘ì¤‘ì•ˆí•¨' íŒë‹¨")
    print("="*60)
    
    if torch.cuda.is_available():
        print(f"ğŸ“Š GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ“Š GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    
    # ì €ì¥ ê²½ë¡œ
    precision_dir = "./log/precision_v2"
    os.makedirs(precision_dir, exist_ok=True)
    os.makedirs(f"{precision_dir}/confusion_matrix", exist_ok=True)
    
    # ë°ì´í„° ë¡œë“œ
    base_path = r"C:\Users\user\Desktop\brainbuddy_AI\preprocess2\pickle_labels"
    train_pkl_files = [
        f"{base_path}\\train\\20_01.pkl",
        f"{base_path}\\train\\20_03.pkl"
    ]
    val_pkl_files = [
        f"{base_path}\\valid\\20_01.pkl",
        f"{base_path}\\valid\\20_03.pkl"
    ]

    train_data_list = load_data(train_pkl_files)
    val_data_list = load_data(val_pkl_files)

    print(f"ğŸ“Š í›ˆë ¨ ë°ì´í„°: {len(train_data_list):,}ê°œ")
    print(f"ğŸ“Š ê²€ì¦ ë°ì´í„°: {len(val_data_list):,}ê°œ")

    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = PrecisionEnhancedDataset(train_data_list, is_training=True)
    val_dataset = PrecisionEnhancedDataset(val_data_list, is_training=False)

    # DataLoader
    batch_size = 4
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, 
                             num_workers=4, pin_memory=True, persistent_workers=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, 
                           num_workers=4, pin_memory=True, persistent_workers=True)

    print(f"ğŸ“Š ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"ğŸ“Š í›ˆë ¨ ë°°ì¹˜: {len(train_loader):,}ê°œ")

    # ëª¨ë¸ ì´ˆê¸°í™”
    cnn = PrecisionEnhancedCNNEncoder().to(device)
    model = PrecisionEnhancedModelV2().to(device)
    
    print("âœ… Precision Enhanced ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
    print(f"   - CNN: 3ì¸µ FC + BatchNorm")
    print(f"   - Transformer: d_model=256, 4 layers")
    print(f"   - íŠ¹ë³„ ê¸°ëŠ¥: Attention Pooling, Confidence Scaling")
    
    # Precision ìµœì í™” ì†ì‹¤ í•¨ìˆ˜
    criterion = PrecisionFocusedLoss(precision_weight=2.5, pos_weight=1.3)
    
    optimizer = torch.optim.AdamW(
        list(cnn.parameters()) + list(model.parameters()), 
        lr=1.5e-4,  # ë” ë‚®ì€ í•™ìŠµë¥ ë¡œ ì•ˆì •ì  í›ˆë ¨
        weight_decay=2e-3  # ê°•í•œ ì •ê·œí™”
    )
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=6, eta_min=5e-6)
    scaler = GradScaler()
    
    # ì €ì¥ ê²½ë¡œ
    best_model_path = f"{precision_dir}/best_precision_model.pt"
    checkpoint_path = f"{precision_dir}/last_precision_checkpoint.pt"
    log_history = []

    print(f"ğŸ¯ ëª©í‘œ: Precision 0.9+ (ì§‘ì¤‘í•˜ëŠ” í•™ìƒì„ ì˜ëª» ì§€ì í•˜ì§€ ì•Šê¸°)")
    print("="*60)

    # í›ˆë ¨ ë£¨í”„
    num_epochs = 6
    patience = 3
    patience_counter = 0
    best_precision = 0.0

    for epoch in range(num_epochs):
        current_lr = scheduler.get_last_lr()[0]
        print(f"\n[Epoch {epoch+1}/{num_epochs}] LR: {current_lr:.2e}")
        
        # í›ˆë ¨
        start_time = time.time()
        train_loss = train_precision_model(model, cnn, train_loader, criterion, optimizer, device, scaler)
        train_time = time.time() - start_time
        
        # ê²€ì¦
        start_time = time.time()
        val_loss = validate_precision_model(model, cnn, val_loader, criterion, device)
        val_time = time.time() - start_time
        
        print(f"[Epoch {epoch+1}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
        print(f"[Epoch {epoch+1}] Time - Train: {train_time/60:.1f}ë¶„, Val: {val_time/60:.1f}ë¶„")

        # ì„±ëŠ¥ í‰ê°€ (ë†’ì€ ì„ê³„ê°’ìœ¼ë¡œ)
        def create_sample_batches(loader, max_batches=50):
            """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ìƒ˜í”Œë§"""
            sample_batches = []
            for i, batch in enumerate(loader):
                if i >= max_batches:
                    break
                sample_batches.append(batch)
                torch.cuda.empty_cache()  # ë°°ì¹˜ë§ˆë‹¤ ë©”ëª¨ë¦¬ ì •ë¦¬
            return sample_batches

        # ì‚¬ìš©
        sample_loader = create_sample_batches(val_loader, max_batches=50)
        accuracy, precision, recall, f1, all_probs = evaluate_precision_metrics(
            model, cnn, sample_loader, device, threshold=0.8
        )
        
        print(f"[Epoch {epoch+1}] Metrics (threshold=0.8)")
        print(f"   - Accuracy: {accuracy:.4f}")
        print(f"   - Precision: {precision:.4f} â­")
        print(f"   - Recall: {recall:.4f}")
        print(f"   - F1-Score: {f1:.4f}")

        log_history.append({
            "epoch": epoch + 1,
            "train_loss": train_loss,
            "val_loss": val_loss,
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1_score": f1,
            "learning_rate": current_lr,
            "train_time_min": train_time/60,
            "val_time_min": val_time/60
        })

        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥ (Precision ê¸°ì¤€)
        if precision > best_precision:
            best_precision = precision
            
            # ì „ì²´ ê²€ì¦ ë°ì´í„°ë¡œ ì„ê³„ê°’ ìµœì í™”
            print("\nğŸ” ì „ì²´ ê²€ì¦ ë°ì´í„°ë¡œ ìµœì  ì„ê³„ê°’ íƒìƒ‰ ì¤‘...")
            all_sample_loader = list(val_loader)[:300]  # ë” ë§ì€ ìƒ˜í”Œë¡œ ì •í™•í•œ ì¸¡ì •
            _, _, _, _, all_validation_probs = evaluate_precision_metrics(
                model, cnn, all_sample_loader, device, threshold=0.5
            )
            
            all_validation_labels = []
            for videos, fusion, labels in all_sample_loader:
                all_validation_labels.extend(labels.int().numpy().flatten())
            
            optimal_threshold, best_metrics = find_optimal_threshold_for_precision(
                all_validation_probs, all_validation_labels, target_precision=0.9
            )
            
            torch.save({
                'cnn_state_dict': cnn.state_dict(),
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'epoch': epoch,
                'val_loss': val_loss,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'optimal_threshold': optimal_threshold,
                'best_metrics': best_metrics,
                'precision_focused': True
            }, best_model_path)
            
            print(f"âœ… Best precision model saved (Precision: {precision:.4f})")
            patience_counter = 0
        else:
            patience_counter += 1
            print(f"Precision improvement patience {patience_counter}/{patience}")
            if patience_counter >= patience:
                print("==== Early stopping Triggered (Precision ê¸°ì¤€) ====")
                break

        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        torch.save({
            'cnn_state_dict': cnn.state_dict(),
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'epoch': epoch,
            'best_precision': best_precision
        }, checkpoint_path)
        
        scheduler.step()

    # ë¡œê·¸ ì €ì¥
    log_df = pd.DataFrame(log_history)
    log_df.to_csv(f"{precision_dir}/precision_training_log.csv", index=False)
    print(f"\nğŸ“„ Training log saved to {precision_dir}/precision_training_log.csv")

    # ìµœì¢… ê²°ê³¼
    if os.path.exists(best_model_path):
        checkpoint = torch.load(best_model_path, map_location=device)
        final_precision = checkpoint.get('precision', 0)
        final_accuracy = checkpoint.get('accuracy', 0)
        final_recall = checkpoint.get('recall', 0)
        final_f1 = checkpoint.get('f1_score', 0)
        optimal_threshold = checkpoint.get('optimal_threshold', 0.8)
        best_metrics = checkpoint.get('best_metrics', {})
        
        print("\n" + "="*60)
        print("ğŸ‰ **Precision Enhanced Version 2 í›ˆë ¨ ì™„ë£Œ!**")
        print("="*60)
        print(f"ğŸ”¸ ê¸°ì¡´ Version 2: 76.9% ì •í™•ë„")
        print(f"ğŸ”¸ Precision Enhanced: {final_accuracy:.1%} ì •í™•ë„")
        print(f"ğŸ”¸ í•µì‹¬ ì„±ê³¼ - Precision: {final_precision:.1%} â­")
        print(f"ğŸ”¸ Recall: {final_recall:.1%}")
        print(f"ğŸ”¸ F1-Score: {final_f1:.1%}")
        print(f"ğŸ”¸ ìµœì  ì„ê³„ê°’: {optimal_threshold:.2f}")
        
        if best_metrics:
            print(f"\nğŸ† **Precision 0.9+ ë‹¬ì„± ì„±ê³µ!**")
            print(f"   - ìµœì¢… Precision: {best_metrics['precision']:.3f}")
            print(f"   - ìµœì¢… Recall: {best_metrics['recall']:.3f}")
            print(f"   - ìµœì¢… F1-Score: {best_metrics['f1']:.3f}")
            print(f"   - ìµœì¢… Accuracy: {best_metrics['accuracy']:.3f}")
            print(f"ğŸ“š êµìœ¡ì  ì˜ë¯¸: ì§‘ì¤‘í•˜ëŠ” í•™ìƒì„ ì˜ëª» ì§€ì í•  í™•ë¥  < 10%")
        
        print(f"ğŸ“ ëª¨ë¸ ì €ì¥: {best_model_path}")
        
        if final_precision >= 0.9:
            print("ğŸ‰ Precision 0.9+ ë‹¬ì„±! ì•ˆì „í•œ ì§‘ì¤‘ë„ íƒì§€ ì‹œìŠ¤í…œ ì™„ì„±!")
        elif final_precision >= 0.85:
            print("ğŸŠ Precision 0.85+ ë‹¬ì„±! ì‹¤ìš©ì  ìˆ˜ì¤€ì˜ ì‹ ë¢°ì„± í™•ë³´!")
        else:
            print("ğŸ“Š ì¶”ê°€ ê°œì„  ì—¬ì§€ê°€ ìˆì§€ë§Œ, ê¸°ì¡´ ëŒ€ë¹„ í–¥ìƒ í™•ì¸")
            
        print("\nğŸ¯ **ì‹¤ì œ í™œìš© ê°€ì´ë“œ**")
        print(f"   - ê¶Œì¥ ì„ê³„ê°’: {optimal_threshold:.2f}")
        print(f"   - AIê°€ 'ì§‘ì¤‘ì•ˆí•¨'ì´ë¼ê³  í•  ë•Œ ì‹ ë¢°ë„: {final_precision:.1%}")
        print(f"   - ì‹¤ì œ ì§‘ì¤‘ ì•ˆ í•˜ëŠ” í•™ìƒ íƒì§€ìœ¨: {final_recall:.1%}")

if __name__ == '__main__':
    main()
