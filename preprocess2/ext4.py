import cv2
import os
import shutil
from tqdm import tqdm
from models.face_crop import crop_face
import mediapipe as mp

def extract_frames(video_path, local_output_base, face_detector, segment_duration=10, target_fps=10, max_frames=100):
    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        print(f"ì˜ìƒ ì—´ê¸° ì‹¤íŒ¨ :{video_path}")
        return

    fps = 30
    frame_interval = max(int(fps / target_fps), 1)
    segment_frame_count = segment_duration * fps
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    num_segments = total_frames // segment_frame_count

    print(f"ğŸ¬ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {num_segments}, Interval: {frame_interval}í”„ë ˆì„ë§ˆë‹¤ ì €ì¥")

    for segment_idx in tqdm(range(num_segments), desc="300í”„ë ˆì„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬"):
        local_segment_dir = os.path.normpath(os.path.join(local_output_base, f"segment_{segment_idx}"))

        if os.path.exists(local_segment_dir):
            jpg_files = [f for f in os.listdir(local_segment_dir) if f.lower().endswith(".jpg")]
            if len(jpg_files) >= max_frames:
                print(f"âœ… ì„¸ê·¸ë¨¼íŠ¸ {segment_idx} ì´ë¯¸ {len(jpg_files)}ì¥ ì¡´ì¬ â†’ ê±´ë„ˆëœ€.")
                continue
            else: #300ì¥ì´ ì•„ë‹ˆë©´ ì§€ìš°ê³  ë®ì–´ì”€
                print(f"â™»ï¸ ì„¸ê·¸ë¨¼íŠ¸ {segment_idx} í”„ë ˆì„ {len(jpg_files)}ì¥ â†’ ë®ì–´ì“°ê¸° ìœ„í•´ ì‚­ì œ í›„ ì¬ì²˜ë¦¬")
                shutil.rmtree(local_segment_dir)

        cap.set(cv2.CAP_PROP_POS_FRAMES, segment_idx * segment_frame_count)

        count = 0
        saved = 0
        retry_count = 0

        os.makedirs(local_segment_dir, exist_ok=True)

        while saved < max_frames:
            current_frame_pos = cap.get(cv2.CAP_PROP_POS_FRAMES)
            if current_frame_pos >= (segment_idx + 1) * segment_frame_count:
                break

            ret, frame = cap.read()
            if not ret:
                if retry_count < 2:
                    retry_count += 1
                    print(f"âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ {segment_idx} í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨, ì¬ì‹œë„ {retry_count}/2... (í”„ë ˆì„: {current_frame_pos})")
                    cap.set(cv2.CAP_PROP_POS_FRAMES, current_frame_pos)
                    continue
                else:
                    print(f"âŒ ì„¸ê·¸ë¨¼íŠ¸ {segment_idx} í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨ ì´ˆê³¼. ê±´ë„ˆëœ€.")
                    break

            retry_count = 0

            if count % frame_interval == 0:
                cropped = crop_face(frame, face_detector)
                if cropped is not None:
                    frame_path = os.path.normpath(os.path.join(local_segment_dir, f"{saved:04d}.jpg"))
                    success = cv2.imwrite(frame_path, cropped, [cv2.IMWRITE_JPEG_QUALITY, 75])
                    if success:
                        saved += 1

            count += 1

        print(f"âœ… ì„¸ê·¸ë¨¼íŠ¸ {segment_idx} ì €ì¥ ì™„ë£Œ ({saved}ì¥)")

    cap.release()
    print("ì „ì²´ ì‘ì—… ì™„ë£Œ")


if __name__ == "__main__":
    mp_face_detection = mp.solutions.face_detection
    face_detector = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)
    for i in range(31,35):
        video_folder = f"C:/Users/user/Downloads/109.í•™ìŠµíƒœë„ ë° ì„±í–¥ ê´€ì°° ë°ì´í„°/3.ê°œë°©ë°ì´í„°/1.ë°ì´í„°/Training/01.ì›ì²œë°ì´í„°/TS_20_01_2/{i}"
        local_root = r"C:/AIhub_frames/train"  # âœ… ë¡œì»¬ ì €ì¥ ìœ„ì¹˜

        video_files = sorted([
            f for f in os.listdir(video_folder)
            if f.lower().endswith(".mp4")
        ])

        for video_file in video_files:
            video_path = os.path.join(video_folder, video_file)
            video_name = os.path.splitext(video_file)[0]
            local_output_base = os.path.join(local_root, video_name)

            extract_frames(video_path, local_output_base, face_detector)
        print(f"================={i}ë²ˆ í´ë” ì „ì²˜ë¦¬ ì™„ë£Œ ===================\n")

    face_detector.close()