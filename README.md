# í”„ë¡œì íŠ¸ ëª…
BrainBuddyAI : Deep Learning Based Engagement Measuring Model (CNN â†’ LSTM)

ë³¸ í”„ë¡œì íŠ¸ëŠ” **CNN â†’ LSTM êµ¬ì¡°**ë¥¼ í™œìš©í•˜ì—¬  
ì˜ìƒ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ì§‘ì¤‘ë„**ë¥¼ ì¸¡ì •í•˜ëŠ” ëª¨ë¸ì„ êµ¬í˜„í•˜ê³ ,  
ë‹¤ì–‘í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ëª¨ë¸ êµ¬ì¡° ë³€ê²½ ì‹¤í—˜ì„ í†µí•´ ìµœì ì˜ ì„±ëŠ¥ì„ íƒìƒ‰í•˜ì˜€ìŠµë‹ˆë‹¤.
<br>

## ê¸°ìˆ  ìŠ¤íƒ
- ì–¸ì–´ & í™˜ê²½
![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python&logoColor=white)
	- Python 3.10.0

- ë”¥ëŸ¬ë‹ / ëª¨ë¸ë§
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?logo=pytorch&logoColor=white)
![Torchvision](https://img.shields.io/badge/Torchvision-%23EE4C2C.svg?logo=pytorch&logoColor=white)
	- PyTorch â€“ ëª¨ë¸ êµ¬í˜„ ë° í•™ìŠµ
	- Torchvision â€“ CNN ë°±ë³¸ ë° ì´ë¯¸ì§€ ë³€í™˜

- ì»´í“¨í„° ë¹„ì „ / ì „ì²˜ë¦¬
![OpenCV](https://img.shields.io/badge/OpenCV-%23white.svg?logo=opencv&logoColor=black)
![Mediapipe](https://img.shields.io/badge/Mediapipe-4285F4?logo=google&logoColor=white)
	- OpenCV â€“ ì˜ìƒ í”„ë ˆì„ ì²˜ë¦¬
	- Mediapipe FaceDetection â€“ ì–¼êµ´ ê²€ì¶œ ë° í¬ë¡­

- í‰ê°€ & ì‹œê°í™”
![scikit-learn](https://img.shields.io/badge/scikit--learn-F7931E.svg?logo=scikit-learn&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-013243.svg?logo=plotly&logoColor=white)
![UMAP](https://img.shields.io/badge/UMAP--learn-5D3FD3.svg?logo=python&logoColor=white)
	- scikit-learn â€“ í‰ê°€ ì§€í‘œ (F1, Recall, Confusion Matrix)
	- Matplotlib â€“ í•™ìŠµ ê³¡ì„ , í˜¼ë™ í–‰ë ¬, ì‹œê°í™”
	- UMAP-learn â€“ ì„ë² ë”© ì°¨ì› ì¶•ì†Œ ë° ì‹œê°í™”
<br>

## ğŸ“‚ í´ë” êµ¬ì¡°(ì˜ˆì‹œ)
project/ <br>
â”£ data/ # ì›ë³¸ ë° ê°€ê³µ ë°ì´í„° <br>
â”£ notebooks/ # EDA, ì‹¤í—˜ìš© Jupyter Notebook <br>
â”£ src/ # ì£¼ìš” Python ì†ŒìŠ¤ì½”ë“œ <br>
â”ƒ â”£ preprocessing.py # ë°ì´í„° ì „ì²˜ë¦¬ ì½”ë“œ <br>
â”ƒ â”£ modeling.py # ëª¨ë¸ ì •ì˜/í•™ìŠµ ì½”ë“œ <br>
â”ƒ â”£ train.py # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ <br>
â”ƒ â”— evaluate.py # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ <br>
â”£ results/ # ê²°ê³¼ (ëª¨ë¸ ì„±ëŠ¥, ê·¸ë˜í”„, ë¡œê·¸)  <br>
â”£ requirements.txt # ì˜ì¡´ì„± íŒ¨í‚¤ì§€  <br>
â”— README.md # ë¦¬ë“œë¯¸ <br>
<br>

## 0. ëª¨ë¸ êµ¬ì¡°
<img src="https://github.com/user-attachments/assets/4aace760-7b52-4cb1-bda2-6202143f7e62" width="500" ><br>
30í”„ë ˆì„ ì‹œí€€ìŠ¤ -> CNN(MobileNetV3-Large) -> LSTM -> ì§‘ì¤‘ì—¬ë¶€(0/1)
<br>

## 1. ë°ì´í„° 
### ì‚¬ìš© ë°ì´í„°ì…‹
AIHub dataset : [í•™ìŠµíƒœë„ ë° ì„±í–¥ ê´€ì°° ë°ì´í„°](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=71715)
 <br>
### ì „ì²˜ë¦¬ ë° ë¼ë²¨ë§
`python -m preprocess2.ext` mediapipeë¡œ facecrop í›„ 10ì´ˆì— 30frameì”© ì¶”ì¶œ

`python -m preprocess2.labeling` (í´ë” ê²½ë¡œ, ë¼ë²¨) ê°’ì„ .pkl ì— ì €ì¥
<br>

## 2. ëª¨ë¸ í•™ìŠµ
`python train.py`
- Epoch: 15
- Early Stopping patience: 4
- Batch size = 8
- Optimizer: AdamW
- Loss Function: BCEWithLogitsLoss + CosineAnnealingLR
- Gradient Accumulation = 32 step
<br>
 
## 3. ëª¨ë¸ í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥
 
| test set |  Accuracy | Recall | F1 |
| --- |--- | --- | --- |
| AIhub test set | 0.8088 | 0.8690 | 0.8149 |
| ìì²´ ê°œë°œ test set | 0.7470 | 0.7823 | 0.7239 |

<br>

ìµœì¢… ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•´ íŒ€ì›ë“¤ì´ ì§ì ‘ ì›¹ìº ìœ¼ë¡œ ì´¬ì˜í•œ 5ë¶„ ë‚´ì™¸ì˜ ìì²´ ê°œë°œ test setì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
<p align="center">
  <img src="https://github.com/user-attachments/assets/f10c8132-fd12-48e8-a942-6c880c4e3ae9" width="49%">
  <img src="https://github.com/user-attachments/assets/e21fd614-98ae-430b-bffc-8d64eddc1d8f" width="49%">
</p>

<br>

## 4. ì§ì ‘ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•´ë³´ê¸°
1. "best_model.pt"ë¥¼ ë‹¤ìš´ë¡œë“œ
2. `real_time.py`ì˜ CKPT_PATHì— í•´ë‹¹ .pt ê²½ë¡œ ì§€ì •
3. `python real_time.py`
 <br>


