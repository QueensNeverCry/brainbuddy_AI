import pickle
import os
from preprocess_and_save_features import preprocess_dataset  # ê¸°ì¡´ ì „ì²˜ë¦¬ í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°

def load_extended_dataset(original_pickle_path, original_root="train_frames", aug_root="train_aug_frames"):
    with open(original_pickle_path, "rb") as f:
        dataset_links = pickle.load(f)

    augmented_links = []
    for path, label in dataset_links:
        if label == 0 and original_root in path:
            aug_path = path.replace(original_root, aug_root) + "_aug"
            if os.path.exists(aug_path):
                augmented_links.append((aug_path, label))
            else:
                print(f"â— ì¦ê°• í´ë” ì—†ìŒ: {aug_path}")
    
    print(f"âœ… ì¦ê°•ëœ ë¼ë²¨ 0 ë°ì´í„° ìˆ˜: {len(augmented_links)}")
    return dataset_links + augmented_links

def count_label_zero(dataset_links):
    return sum(1 for _, label in dataset_links if label == 0)

if __name__ == "__main__":
    # ğŸŸ¡ ì›ë³¸ + ì¦ê°• í•™ìŠµ ë°ì´í„° ë³‘í•©
    extended_train_link = load_extended_dataset(
        original_pickle_path="train_link.pkl",
        original_root="train_frames",
        aug_root="train_aug_frames"
    )

    # ğŸŸ¡ Validationì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    with open("val_link.pkl", "rb") as f:
        val_link = pickle.load(f)

    # ğŸŸ¢ CNN Feature ì „ì²˜ë¦¬ ì €ì¥
    preprocess_dataset(extended_train_link, save_dir="preprocessed_features/train_data", T=10)
    preprocess_dataset(val_link, save_dir="preprocessed_features/val_data", T=10)

    # âœ… ì¶œë ¥
    print(f"âœ… ìµœì¢… í•™ìŠµ ë°ì´í„° ìˆ˜: {len(extended_train_link)}ê°œ")
    print(f"âœ… ìµœì¢… ê²€ì¦ ë°ì´í„° ìˆ˜: {len(val_link)}ê°œ")
    print(f"âœ… ìµœì¢… í•™ìŠµ ë°ì´í„° ì¤‘ ë¼ë²¨ 0 ê°œìˆ˜: {count_label_zero(extended_train_link)}ê°œ")
