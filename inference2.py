# inference2.py (Version 2 ëª¨ë¸ ì „ìš© í…ŒìŠ¤íŠ¸)
import os
import pickle
import cv2
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
from tqdm import tqdm
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import math  # Positional Encodingì„ ìœ„í•´ ì¶”ê°€

from sklearn.metrics import (
    confusion_matrix,
    ConfusionMatrixDisplay,
    accuracy_score,
    recall_score,
    f1_score
)

# ------------------ Dataset (Version 2 í˜¸í™˜) ------------------
class VideoFolderDataset(Dataset):
    def __init__(self, data_list, transform=None):
        self.data_list = []
        self.transform = transform or transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        for folder_path, label in data_list:
            if os.path.isdir(folder_path):
                img_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                if len(img_files) >= 30:
                    self.data_list.append((folder_path, label))

    def __len__(self):
        return len(self.data_list)

    def __getitem__(self, idx):
        folder_path, label = self.data_list[idx]
        img_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])[:30]
        frames = []
        
        for f in img_files:
            img_path = os.path.join(folder_path, f)
            try:
                img_pil = Image.open(img_path).convert('RGB')
                frames.append(self.transform(img_pil))
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
                continue
        
        # 30ê°œ í”„ë ˆì„ ë³´ì¥
        while len(frames) < 30:
            frames.append(frames[-1] if frames else torch.zeros(3, 224, 224))
        
        video = torch.stack(frames[:30])  # ì •í™•íˆ 30ê°œë§Œ

        fusion_path = os.path.join(folder_path, "fusion_features.pkl")
        if os.path.exists(fusion_path):
            with open(fusion_path, 'rb') as f:
                fusion = torch.tensor(pickle.load(f), dtype=torch.float32)
        else:
            fusion = torch.zeros(5)

        # ë¼ë²¨ ì²˜ë¦¬ (ë¬¸ìì—´ â†’ ìˆ«ì ë³€í™˜)
        if isinstance(label, str):
            if label == 'ì§‘ì¤‘í•˜ì§€ì•ŠìŒ':
                label = 1
            else:
                label = 0  # ê¸°ë³¸ê°’

        return video, fusion, torch.tensor(label, dtype=torch.float32)

# ------------------ Version 2 CNNEncoder ------------------
class CNNEncoder(nn.Module):
    def __init__(self, output_dim=1280):
        super().__init__()
        mobilenet = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)
        self.features = mobilenet.features
        self.avgpool = nn.AdaptiveAvgPool2d((4, 4))
        
        # âœ… Version 2ì™€ ë™ì¼í•œ FC ë ˆì´ì–´ (BatchNorm ì¶”ê°€)
        self.fc = nn.Sequential(
            nn.Linear(1280 * 4 * 4, 2048),
            nn.BatchNorm1d(2048),  # BatchNorm ì¶”ê°€
            nn.ReLU(),
            nn.Dropout(0.4),  # ë“œë¡­ì•„ì›ƒ ì¦ê°€
            nn.Linear(2048, output_dim),
            nn.BatchNorm1d(output_dim),
            nn.ReLU()
        )

    def forward(self, x):  # x: (B, 30, 3, 224, 224)
        B, T, C, H, W = x.shape
        x = x.view(B * T, C, H, W)
        x = self.features(x)
        x = self.avgpool(x)
        x = x.view(B * T, -1)
        x = self.fc(x)
        return x.view(B, T, -1)

# ------------------ Version 2 Transformer ëª¨ë¸ ------------------
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super().__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)

    def forward(self, x):
        seq_len = x.size(0)
        return x + self.pe[:seq_len, :].to(x.device)

class EngagementModelV2(nn.Module):
    def __init__(self, cnn_feat_dim=1280, fusion_feat_dim=5, d_model=256, nhead=8, num_layers=4):
        super().__init__()
        
        # âœ… Version 2 ì…ë ¥ í”„ë¡œì ì…˜ (LayerNorm í¬í•¨)
        self.input_projection = nn.Sequential(
            nn.Linear(cnn_feat_dim, d_model),
            nn.LayerNorm(d_model),  # LayerNorm ì¶”ê°€
            nn.ReLU(),
            nn.Dropout(0.1)
        )
        
        # Positional Encoding
        self.pos_encoder = PositionalEncoding(d_model)
        
        # âœ… Version 2 ê°œì„ ëœ Transformer Encoder Layer
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 4,
            dropout=0.15,  # ë“œë¡­ì•„ì›ƒ ì¦ê°€
            activation='gelu',  # ReLU â†’ GELU
            batch_first=True,
            norm_first=True  # Pre-LN êµ¬ì¡°
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # âœ… Version 2 ê°œì„ ëœ Pooling (Max + Average ì¡°í•©)
        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)
        self.global_max_pool = nn.AdaptiveMaxPool1d(1)
        
        # âœ… Version 2 ë” ë³µì¡í•œ ìµœì¢… ë¶„ë¥˜ê¸°
        self.fc = nn.Sequential(
            nn.Linear(d_model * 2 + fusion_feat_dim, 512),  # Max + Avg pooling
            nn.LayerNorm(512),
            nn.GELU(),
            nn.Dropout(0.2),
            nn.Linear(512, 128),
            nn.LayerNorm(128),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(128, 1)
        )

    def forward(self, cnn_feats, fusion_feats):
        # ì…ë ¥ í”„ë¡œì ì…˜
        x = self.input_projection(cnn_feats)  # (B, T, d_model)
        
        # Positional Encoding ì¶”ê°€ (ì‹œí€€ìŠ¤ ìˆœì„œ ì •ë³´)
        x = x.transpose(0, 1)  # (T, B, d_model)
        x = self.pos_encoder(x)
        x = x.transpose(0, 1)  # (B, T, d_model)
        
        # Transformer Encoder
        transformer_out = self.transformer_encoder(x)  # (B, T, d_model)
        
        # âœ… Max + Average Pooling ì¡°í•©
        avg_pooled = self.global_avg_pool(transformer_out.transpose(1, 2)).squeeze(-1)  # (B, d_model)
        max_pooled = self.global_max_pool(transformer_out.transpose(1, 2)).squeeze(-1)  # (B, d_model)
        pooled = torch.cat([avg_pooled, max_pooled], dim=1)  # (B, d_model * 2)
        
        # Fusion features ê²°í•©
        combined = torch.cat([pooled, fusion_feats], dim=1)  # (B, d_model * 2 + 5)
        
        # ìµœì¢… ì¶œë ¥
        return self.fc(combined)

# ------------------ Utils ------------------
def load_data(pkl_files):
    all_data = []
    for pkl_path in pkl_files:
        if not os.path.exists(pkl_path):
            print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pkl_path}")
            continue
        with open(pkl_path, 'rb') as f:
            data = pickle.load(f)  # [(folder_path, label), ...]
            all_data.extend(data)
            print(f"âœ… ë¡œë“œë¨: {pkl_path} ({len(data)}ê°œ ìƒ˜í”Œ)")
    return all_data

def test_multiple_thresholds(all_probs, all_labels):
    """ì—¬ëŸ¬ ì„ê³„ê°’ìœ¼ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ¯ **ì„ê³„ê°’ë³„ ì„±ëŠ¥ ë¹„êµ**")
    print("="*60)
    
    best_threshold = 0.5
    best_f1 = 0.0
    
    for threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:
        preds = (np.array(all_probs) >= threshold).astype(np.int32)
        acc = accuracy_score(all_labels, preds)
        rec = recall_score(all_labels, preds, zero_division=0)
        f1 = f1_score(all_labels, preds, zero_division=0)
        
        print(f"Threshold {threshold:.1f}: Acc={acc:.4f} | Rec={rec:.4f} | F1={f1:.4f}")
        
        if f1 > best_f1:
            best_f1 = f1
            best_threshold = threshold
    
    print(f"\nğŸ† **ìµœì  ì„ê³„ê°’: {best_threshold:.1f} (F1={best_f1:.4f})**")
    return best_threshold

# ------------------ Main Test Function ------------------
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”¥ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    print("ğŸš€ **Version 2 ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘**")
    print("="*60)

    # âœ… Version 2 ëª¨ë¸ ê²½ë¡œ
    best_model_path = "./log/v2/best_model_v2.pt"
    
    # âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ (ë” í¬ê´„ì )
    test_pkl_files = [
        
        "./preprocess2/pickle_labels/valid/20_02.pkl",  # ìƒˆë¡œìš´ ë°ì´í„°
        "./preprocess2/pickle_labels/valid/20_04.pkl",  # ëŒ€ìš©ëŸ‰ ë°ì´í„°
    ]

    # ë°ì´í„° ë¡œë“œ
    test_data_list = load_data(test_pkl_files)
    if len(test_data_list) == 0:
        print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    print(f"ğŸ“Š ì´ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data_list):,}ê°œ")
    
    test_dataset = VideoFolderDataset(test_data_list)
    test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=4, pin_memory=True)

    # âœ… Version 2 ëª¨ë¸ ì´ˆê¸°í™” (d_model=256, num_layers=4)
    cnn = CNNEncoder().to(device)
    model = EngagementModelV2(d_model=256, nhead=8, num_layers=4).to(device)

    if not os.path.exists(best_model_path):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {best_model_path}")
        print("ë‹¤ìŒ ê²½ë¡œë“¤ì„ í™•ì¸í•´ë³´ì„¸ìš”:")
        print("  - ./log/v2/best_model_v2.pt")
        print("  - ./log/best_model2.pt")
        return

    print(f"ğŸ“‚ Version 2 ëª¨ë¸ ë¡œë”© ì¤‘: {best_model_path}")
    try:
        ckpt = torch.load(best_model_path, map_location=device)
        cnn.load_state_dict(ckpt['cnn_state_dict'])
        model.load_state_dict(ckpt['model_state_dict'])
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        if 'epoch' in ckpt:
            print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (Epoch {ckpt['epoch'] + 1}, Val Loss: {ckpt.get('val_loss', 'N/A'):.4f})")
        else:
            print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return

    cnn.eval()
    model.eval()

    # ì¶”ë¡  & ë©”íŠ¸ë¦­
    all_probs, all_preds, all_labels = [], [], []

    print("\nğŸ”„ ì¶”ë¡  ì‹œì‘...")
    with torch.no_grad():
        for videos, fusion, labels in tqdm(test_loader, desc="Version 2 Test"):
            videos = videos.to(device, non_blocking=True)
            fusion = fusion.to(device, non_blocking=True)
            
            # CNN íŠ¹ì§• ì¶”ì¶œ
            feats = cnn(videos)
            
            # Transformer ì¶”ë¡ 
            logits = model(feats, fusion)
            probs = torch.sigmoid(logits).squeeze(1).detach().cpu().numpy()
            
            # ê¸°ë³¸ ì„ê³„ê°’ 0.5ë¡œ ì˜ˆì¸¡
            preds = (probs >= 0.5).astype(np.int32)
            labels = labels.int().numpy()

            all_probs.extend(probs.tolist())
            all_preds.extend(preds.tolist())
            all_labels.extend(labels.tolist())

    # âœ… ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    acc = accuracy_score(all_labels, all_preds)
    rec = recall_score(all_labels, all_preds, zero_division=0)
    f1 = f1_score(all_labels, all_preds, zero_division=0)
    cm = confusion_matrix(all_labels, all_preds)

    print("\n" + "="*60)
    print("ğŸ“Š **Version 2 í…ŒìŠ¤íŠ¸ ê²°ê³¼ (ì„ê³„ê°’ 0.5)**")
    print("="*60)
    print(f"âœ… Accuracy: {acc:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}")
    print("\nConfusion Matrix:")
    print(cm)
    
    # í´ë˜ìŠ¤ë³„ ë¶„í¬ ì¶œë ¥
    unique, counts = np.unique(all_labels, return_counts=True)
    print(f"\nğŸ“‹ ì‹¤ì œ ë¼ë²¨ ë¶„í¬: {dict(zip(unique, counts))}")
    unique, counts = np.unique(all_preds, return_counts=True)
    print(f"ğŸ“‹ ì˜ˆì¸¡ ë¼ë²¨ ë¶„í¬: {dict(zip(unique, counts))}")

    # âœ… ì—¬ëŸ¬ ì„ê³„ê°’ìœ¼ë¡œ ìµœì í™”
    best_threshold = test_multiple_thresholds(all_probs, all_labels)
    
    # ìµœì  ì„ê³„ê°’ìœ¼ë¡œ ì¬ê³„ì‚°
    best_preds = (np.array(all_probs) >= best_threshold).astype(np.int32)
    best_acc = accuracy_score(all_labels, best_preds)
    best_rec = recall_score(all_labels, best_preds, zero_division=0)
    best_f1 = f1_score(all_labels, best_preds, zero_division=0)
    best_cm = confusion_matrix(all_labels, best_preds)

    print("\n" + "="*60)
    print(f"ğŸ“Š **Version 2 ìµœì í™” ê²°ê³¼ (ì„ê³„ê°’ {best_threshold:.1f})**")
    print("="*60)
    print(f"ğŸ† Accuracy: {best_acc:.4f} | Recall: {best_rec:.4f} | F1: {best_f1:.4f}")
    
    # âœ… í˜¼ë™í–‰ë ¬ ì €ì¥
    save_dir = "./log/v2/test_results"
    os.makedirs(os.path.join(save_dir, "confusion_matrix"), exist_ok=True)
    
    # ê¸°ë³¸ ì„ê³„ê°’ í˜¼ë™í–‰ë ¬
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["ì§‘ì¤‘í•¨", "ì§‘ì¤‘í•˜ì§€ì•ŠìŒ"])
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Version 2 Confusion Matrix (Threshold 0.5)")
    out_path_basic = os.path.join(save_dir, "confusion_matrix", "conf_matrix_v2_basic.png")
    plt.savefig(out_path_basic, dpi=200, bbox_inches="tight")
    plt.close()
    
    # ìµœì  ì„ê³„ê°’ í˜¼ë™í–‰ë ¬
    disp_best = ConfusionMatrixDisplay(confusion_matrix=best_cm, display_labels=["ì§‘ì¤‘í•¨", "ì§‘ì¤‘í•˜ì§€ì•ŠìŒ"])
    disp_best.plot(cmap=plt.cm.Blues)
    plt.title(f"Version 2 Confusion Matrix (Optimal Threshold {best_threshold:.1f})")
    out_path_best = os.path.join(save_dir, "confusion_matrix", f"conf_matrix_v2_optimal_{best_threshold:.1f}.png")
    plt.savefig(out_path_best, dpi=200, bbox_inches="tight")
    plt.close()
    
    print(f"ğŸ“Š Confusion matrices saved:")
    print(f"  - Basic (0.5): {out_path_basic}")
    print(f"  - Optimal ({best_threshold:.1f}): {out_path_best}")

    # âœ… ì„±ëŠ¥ ë¹„êµ (Version 1ê³¼ ë¹„êµìš©)
    print("\n" + "="*60)
    print("ğŸ“ˆ **ì„±ëŠ¥ ìš”ì•½**")
    print("="*60)
    print(f"ğŸ”¸ Version 1 (ê¸°ì¡´): 72.5% ì •í™•ë„")
    print(f"ğŸ”¸ Version 2 (ê¸°ë³¸): {acc:.1%} ì •í™•ë„")
    print(f"ğŸ”¸ Version 2 (ìµœì ): {best_acc:.1%} ì •í™•ë„")
    
    if best_acc > 0.725:
        print("ğŸ‰ Version 2ê°€ Version 1ë³´ë‹¤ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤!")
    elif best_acc > 0.70:
        print("âœ… Version 2 ì„±ëŠ¥ì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
    else:
        print("âš ï¸ Version 2ì—ì„œ ê³¼ì í•©ì´ ë°œìƒí•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
