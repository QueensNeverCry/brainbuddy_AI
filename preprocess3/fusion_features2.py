# -*- coding: utf-8 -*-
"""
AIHub í”„ë ˆì„ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ (Thread/Process ì„ íƒí˜•)
- ê¸°ë³¸: ThreadPool (pickle ì—ëŸ¬ íšŒí”¼, ê°€ì¥ ì•ˆì •ì )
- ì˜µì…˜: --mode process (Windowsì—ì„œ spawn + ì•ˆì •í™” ì„¤ì •)

ì‚¬ìš© ì˜ˆ:
python preprocess.py --base-dir "C:/AIhub_frames/test" --mode thread
python preprocess.py --base-dir "C:/AIhub_frames/test" --mode process
"""

import os
import cv2
import pickle
import argparse
import multiprocessing as mp
from tqdm import tqdm
import numpy as np

# mediapipeëŠ” ë¬´ê±°ìš°ë¯€ë¡œ import ì‹œì ì€ ì „ì—­ ìœ ì§€í•˜ë˜, ê°ì²´ ìƒì„±ì€ ë°˜ë“œì‹œ ì›Œì»¤ ë‚´ë¶€ì—ì„œ!
import mediapipe as mp_solutions


# ===== ì„¤ì • ê¸°ë³¸ê°’ =====
DEFAULT_BASE_DIR = r"C:/AIhub_frames/test"
FUSION_FEATURE_DIM = 5
IMAGE_SIZE = (640, 360)


# ===== FaceMesh ì´ˆê¸°í™” (ì›Œì»¤ ë‚´ë¶€ì—ì„œë§Œ í˜¸ì¶œ) =====
def init_face_mesh():
    # static_image_mode=True: ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ì— ì í•©
    return mp_solutions.solutions.face_mesh.FaceMesh(static_image_mode=True)


# ===== ê°œë³„ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ =====
def process_segment(segment_path):
    """
    segment_path ë‚´ë¶€ì—ì„œ 0001.jpg ... ë“±ì˜ í”„ë ˆì„ 30ì¥ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê³ 
    fusion_features.pkl ë¡œ ì €ì¥. ë¬¸ì œ ì‹œ ê°„ë‹¨í•œ ì—ëŸ¬ ë¬¸ìì—´ ë°˜í™˜, ì •ìƒ ì‹œ None ë°˜í™˜.
    """
    try:
        fusion_feat_path = os.path.join(segment_path, "fusion_features.pkl")
        if os.path.exists(fusion_feat_path):
            return None  # ì´ë¯¸ ì²˜ë¦¬ë¨

        # í”„ë ˆì„ íŒŒì¼ ìˆ˜ì§‘
        try:
            files = os.listdir(segment_path)
        except Exception as e:
            return f"ERR|listdir|{segment_path}|{e}"

        image_files = sorted([
            f for f in files
            if f.lower().endswith(".jpg") and f[:4].isdigit()
        ])

        if len(image_files) < 30:
            return f"WARN|few_frames|{segment_path}|{len(image_files)}"

        image_files = image_files[:30]

        # ì›Œì»¤ ì•ˆì—ì„œ FaceMesh ìƒì„±
        face_mesh = init_face_mesh()

        yaw_list, pitch_list, head_movement = [], [], []
        eye_closed_frames = 0
        yawn_detected = 0
        prev_nose = None

        for fname in image_files:
            img_path = os.path.join(segment_path, fname)
            image = cv2.imread(img_path)
            if image is None:
                continue

            image = cv2.resize(image, IMAGE_SIZE)
            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = face_mesh.process(rgb)

            if not results.multi_face_landmarks:
                continue

            landmarks = results.multi_face_landmarks[0].landmark

            # ë¨¸ë¦¬ ì´ë™ (ì½” í¬ì¸íŠ¸ ê¸°ì¤€)
            nose = landmarks[1]
            if prev_nose is not None:
                dx = nose.x - prev_nose.x
                dy = nose.y - prev_nose.y
                head_movement.append((dx * dx + dy * dy) ** 0.5)
            prev_nose = nose

            # í•˜í’ˆ (ì…ìˆ  ê±°ë¦¬)
            lip_dist = abs(landmarks[13].y - landmarks[14].y)
            if lip_dist > 0.05:
                yawn_detected = 1

            # ëˆˆ ê°ê¹€ (ìœ—/ì•„ë«ëˆˆêº¼í’€ ì‚¬ì´)
            eye_openness = abs(landmarks[159].y - landmarks[145].y)
            if eye_openness < 0.015:
                eye_closed_frames += 1

            # ì–¼êµ´ ê°ë„ ëŒ€ìš© íŠ¹ì§• (ì¢Œìš°/ìƒí•˜ ëœë“œë§ˆí¬ ì°¨)
            yaw = landmarks[263].x - landmarks[33].x
            pitch = landmarks[152].y - landmarks[10].y
            yaw_list.append(yaw)
            pitch_list.append(pitch)

        # í†µê³„ëŸ‰ ê³„ì‚°
        yaw_diff = np.std(np.diff(yaw_list)) if len(yaw_list) > 1 else 0.0
        pitch_diff = np.std(np.diff(pitch_list)) if len(pitch_list) > 1 else 0.0
        eye_closed_ratio = float(eye_closed_frames) / 30.0
        head_speed = float(np.mean(head_movement)) if head_movement else 0.0

        features = [float(yaw_diff), float(pitch_diff),
                    float(yawn_detected), float(eye_closed_ratio), float(head_speed)]

        if len(features) != FUSION_FEATURE_DIM:
            return f"ERR|feat_dim|{segment_path}|{len(features)}"

        # ê²°ê³¼ ì €ì¥ (pickle)
        try:
            with open(fusion_feat_path, "wb") as f:
                pickle.dump(features, f)
        except Exception as e:
            return f"ERR|pickle_dump|{segment_path}|{e}"

        return None  # ì„±ê³µ

    except Exception as e:
        # ì›Œì»¤ ë‚´ë¶€ ì˜ˆì™¸ëŠ” ê°„ë‹¨ ë¬¸ìì—´ë¡œ ë°˜í™˜(ì´ëª¨ì§€/íŠ¹ìˆ˜ë¬¸ì ì œì™¸)
        return f"ERR|exception|{segment_path}|{e}"


# ===== ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ ê²½ë¡œ ìˆ˜ì§‘ =====
def get_all_segment_paths(base_dir):
    all_segments = []
    try:
        subjects = os.listdir(base_dir)
    except Exception:
        return all_segments

    for subject_folder in subjects:
        subject_path = os.path.join(base_dir, subject_folder)
        if not os.path.isdir(subject_path):
            continue
        try:
            segments = os.listdir(subject_path)
        except Exception:
            continue
        for segment_folder in segments:
            segment_path = os.path.join(subject_path, segment_folder)
            if os.path.isdir(segment_path):
                all_segments.append(segment_path)
    return all_segments


# ===== ì‹¤í–‰ ëª¨ë“œ: ThreadPool =====
def run_threaded(segment_paths, workers):
    errors = []
    # ThreadPool ì€ multiprocessing.dummy ì‚¬ìš©
    from multiprocessing.dummy import Pool as ThreadPool

    with ThreadPool(processes=workers) as pool:
        for result in tqdm(pool.imap_unordered(process_segment, segment_paths), total=len(segment_paths)):
            if result is not None:
                errors.append(result)
    return errors


# ===== ì‹¤í–‰ ëª¨ë“œ: Process Pool (Windows ì•ˆì •í™”) =====
def run_process(segment_paths, workers):
    errors = []

    # OpenCV ë‚´ë¶€ ìŠ¤ë ˆë“œ ë¹„í™œì„±í™”(ì¶©ëŒ ë°©ì§€)
    try:
        cv2.setNumThreads(1)
    except Exception:
        pass

    # Windows ê¸°ë³¸ spawnì„ ëª…ì‹œ, ì‘ì—…ì ìˆ˜ëª… ì œí•œ
    ctx = mp.get_context("spawn")
    with ctx.Pool(processes=workers, maxtasksperchild=1) as pool:
        # chunksize=1: íŒŒì´í”„ ë²„í¼ì— í° ë©ì–´ë¦¬ ì•ˆ ìŒ“ì´ë„ë¡
        for result in tqdm(pool.imap_unordered(process_segment, segment_paths, chunksize=1),
                           total=len(segment_paths)):
            if result is not None:
                errors.append(result)
    return errors


def parse_args():
    p = argparse.ArgumentParser(description="AIHub í”„ë ˆì„ ì „ì²˜ë¦¬ (MediaPipe FaceMesh íŠ¹ì§• ì¶”ì¶œ)")
    p.add_argument("--base-dir", type=str, default=DEFAULT_BASE_DIR, help="ì„¸ê·¸ë¨¼íŠ¸ ë£¨íŠ¸ í´ë”")
    p.add_argument("--mode", type=str, choices=["thread", "process"], default="process",
                   help="ì‹¤í–‰ ëª¨ë“œ ì„ íƒ (ê¸°ë³¸ process)")
    p.add_argument("--workers", type=int, default=max(1, mp.cpu_count()//2),
                   help="ë™ì‹œ ì‘ì—…ì ìˆ˜ (ê¸°ë³¸: CPU-1)")
    return p.parse_args()


def main():
    args = parse_args()

    base_dir = args.base_dir
    mode = args.mode
    workers = max(1, args.workers)

    print(f"ğŸ“‚ ë² ì´ìŠ¤ ê²½ë¡œ: {base_dir}")
    print(f"âš™ï¸  ì‹¤í–‰ ëª¨ë“œ: {mode} | workers={workers}")

    segment_paths = get_all_segment_paths(base_dir)
    print(f"ğŸ§© ì´ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(segment_paths)}")

    if not segment_paths:
        print("ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. --base-dir ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    if mode == "thread":
        errors = run_threaded(segment_paths, workers)
    else:
        errors = run_process(segment_paths, workers)

    print("\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
    if errors:
        print(f"\nâš ï¸ ì˜¤ë¥˜/ìŠ¤í‚µ {len(errors)}ê°œ:")
        for e in errors:
            print(e)


if __name__ == "__main__":
    # Windowsì—ì„œ multiprocessing ì‚¬ìš© ì‹œ í•„ìš” (íŠ¹íˆ .exe ë¹Œë“œë‚˜ IDLE ë“±)
    mp.freeze_support()
    main()
